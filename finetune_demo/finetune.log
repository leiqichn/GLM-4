Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]Loading checkpoint shards:  10%|█         | 1/10 [00:00<00:00,  9.89it/s]Loading checkpoint shards:  30%|███       | 3/10 [00:00<00:00, 12.24it/s]Loading checkpoint shards:  50%|█████     | 5/10 [00:00<00:00, 12.72it/s]Loading checkpoint shards:  70%|███████   | 7/10 [00:00<00:00, 13.04it/s]Loading checkpoint shards:  90%|█████████ | 9/10 [00:00<00:00, 12.16it/s]Loading checkpoint shards: 100%|██████████| 10/10 [00:00<00:00, 12.34it/s]
trainable params: 2,785,280 || all params: 9,402,736,640 || trainable%: 0.0296
Map:   0%|          | 0/2690 [00:00<?, ? examples/s]Map:  37%|███▋      | 1000/2690 [00:02<00:04, 378.32 examples/s]Map:  74%|███████▍  | 2000/2690 [00:04<00:01, 408.10 examples/s]Map: 100%|██████████| 2690/2690 [00:06<00:00, 408.40 examples/s]Map: 100%|██████████| 2690/2690 [00:06<00:00, 404.41 examples/s]
train_dataset: Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 2690
})
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 103.90 examples/s]
val_dataset: Dataset({
    features: ['input_ids', 'output_ids'],
    num_rows: 1
})
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|██████████| 1/1 [00:00<00:00, 116.00 examples/s]
max_steps is given, it will override any value given in num_train_epochs
test_dataset: Dataset({
    features: ['input_ids', 'output_ids'],
    num_rows: 1
})
[2024-08-04 15:14:04,937] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
***** Running training *****
  Num examples = 2,690
  Num Epochs = 1
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 1
  Gradient Accumulation steps = 1
  Total optimization steps = 1,000
  Number of trainable parameters = 2,785,280
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4
[93m [WARNING] [0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible
  0%|          | 0/1000 [00:00<?, ?it/s]/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
  0%|          | 1/1000 [00:01<31:12,  1.87s/it]  0%|          | 2/1000 [00:02<16:43,  1.01s/it]  0%|          | 3/1000 [00:02<11:51,  1.40it/s]  0%|          | 4/1000 [00:03<09:47,  1.69it/s]  0%|          | 5/1000 [00:03<08:38,  1.92it/s]  1%|          | 6/1000 [00:03<07:57,  2.08it/s]  1%|          | 7/1000 [00:04<07:31,  2.20it/s]  1%|          | 8/1000 [00:04<07:11,  2.30it/s]  1%|          | 9/1000 [00:05<08:10,  2.02it/s]  1%|          | 10/1000 [00:05<07:37,  2.16it/s]                                                   1%|          | 10/1000 [00:05<07:37,  2.16it/s]  1%|          | 11/1000 [00:06<07:16,  2.27it/s]  1%|          | 12/1000 [00:06<06:54,  2.38it/s]  1%|▏         | 13/1000 [00:06<06:47,  2.42it/s]  1%|▏         | 14/1000 [00:07<06:32,  2.51it/s]  2%|▏         | 15/1000 [00:07<06:23,  2.57it/s]  2%|▏         | 16/1000 [00:07<06:15,  2.62it/s]  2%|▏         | 17/1000 [00:08<06:18,  2.60it/s]  2%|▏         | 18/1000 [00:08<06:11,  2.64it/s]  2%|▏         | 19/1000 [00:09<06:26,  2.54it/s]  2%|▏         | 20/1000 [00:09<06:13,  2.63it/s]                                                   2%|▏         | 20/1000 [00:09<06:13,  2.63it/s]  2%|▏         | 21/1000 [00:09<06:16,  2.60it/s]  2%|▏         | 22/1000 [00:10<06:16,  2.60it/s]  2%|▏         | 23/1000 [00:10<06:10,  2.64it/s]  2%|▏         | 24/1000 [00:11<06:26,  2.52it/s]  2%|▎         | 25/1000 [00:11<06:24,  2.54it/s]  3%|▎         | 26/1000 [00:11<06:23,  2.54it/s]  3%|▎         | 27/1000 [00:12<06:35,  2.46it/s]  3%|▎         | 28/1000 [00:12<06:42,  2.42it/s]  3%|▎         | 29/1000 [00:13<06:33,  2.47it/s]  3%|▎         | 30/1000 [00:13<06:40,  2.42it/s]                                                   3%|▎         | 30/1000 [00:13<06:40,  2.42it/s]  3%|▎         | 31/1000 [00:13<06:45,  2.39it/s]  3%|▎         | 32/1000 [00:14<06:50,  2.36it/s]  3%|▎         | 33/1000 [00:14<06:42,  2.40it/s]  3%|▎         | 34/1000 [00:15<07:00,  2.30it/s]  4%|▎         | 35/1000 [00:15<06:50,  2.35it/s]  4%|▎         | 36/1000 [00:16<06:40,  2.41it/s]  4%|▎         | 37/1000 [00:16<06:21,  2.52it/s]  4%|▍         | 38/1000 [00:16<06:22,  2.51it/s]  4%|▍         | 39/1000 [00:17<06:10,  2.59it/s]  4%|▍         | 40/1000 [00:17<06:23,  2.50it/s]                                                   4%|▍         | 40/1000 [00:17<06:23,  2.50it/s]  4%|▍         | 41/1000 [00:17<06:13,  2.57it/s]  4%|▍         | 42/1000 [00:18<06:16,  2.54it/s]  4%|▍         | 43/1000 [00:18<06:16,  2.54it/s]  4%|▍         | 44/1000 [00:19<06:27,  2.47it/s]  4%|▍         | 45/1000 [00:19<06:26,  2.47it/s]  5%|▍         | 46/1000 [00:19<06:23,  2.49it/s]  5%|▍         | 47/1000 [00:20<06:08,  2.58it/s]  5%|▍         | 48/1000 [00:20<05:59,  2.65it/s]  5%|▍         | 49/1000 [00:21<06:04,  2.61it/s]  5%|▌         | 50/1000 [00:21<06:06,  2.59it/s]                                                   5%|▌         | 50/1000 [00:21<06:06,  2.59it/s]Saving model checkpoint to ./output/checkpoint-50
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
  5%|▌         | 51/1000 [00:21<06:28,  2.44it/s]  5%|▌         | 52/1000 [00:22<06:25,  2.46it/s]  5%|▌         | 53/1000 [00:22<06:13,  2.53it/s]  5%|▌         | 54/1000 [00:23<06:15,  2.52it/s]  6%|▌         | 55/1000 [00:23<06:16,  2.51it/s]  6%|▌         | 56/1000 [00:23<06:09,  2.56it/s]  6%|▌         | 57/1000 [00:24<07:01,  2.24it/s]  6%|▌         | 58/1000 [00:24<07:01,  2.24it/s]  6%|▌         | 59/1000 [00:25<06:59,  2.24it/s]  6%|▌         | 60/1000 [00:25<06:48,  2.30it/s]                                                   6%|▌         | 60/1000 [00:25<06:48,  2.30it/s]  6%|▌         | 61/1000 [00:26<06:50,  2.29it/s]  6%|▌         | 62/1000 [00:26<06:38,  2.35it/s]  6%|▋         | 63/1000 [00:27<06:42,  2.33it/s]  6%|▋         | 64/1000 [00:27<06:37,  2.36it/s]  6%|▋         | 65/1000 [00:27<06:21,  2.45it/s]  7%|▋         | 66/1000 [00:28<06:16,  2.48it/s]  7%|▋         | 67/1000 [00:28<06:15,  2.48it/s]  7%|▋         | 68/1000 [00:29<06:17,  2.47it/s]  7%|▋         | 69/1000 [00:29<06:25,  2.42it/s]  7%|▋         | 70/1000 [00:29<06:19,  2.45it/s]                                                   7%|▋         | 70/1000 [00:29<06:19,  2.45it/s]  7%|▋         | 71/1000 [00:30<06:25,  2.41it/s]  7%|▋         | 72/1000 [00:30<06:20,  2.44it/s]  7%|▋         | 73/1000 [00:31<06:24,  2.41it/s]  7%|▋         | 74/1000 [00:31<06:12,  2.49it/s]  8%|▊         | 75/1000 [00:31<06:09,  2.50it/s]  8%|▊         | 76/1000 [00:32<06:08,  2.51it/s]  8%|▊         | 77/1000 [00:32<06:09,  2.50it/s]  8%|▊         | 78/1000 [00:33<06:08,  2.50it/s]  8%|▊         | 79/1000 [00:33<06:18,  2.43it/s]  8%|▊         | 80/1000 [00:34<06:58,  2.20it/s]                                                   8%|▊         | 80/1000 [00:34<06:58,  2.20it/s]  8%|▊         | 81/1000 [00:34<06:43,  2.28it/s]  8%|▊         | 82/1000 [00:34<06:30,  2.35it/s]  8%|▊         | 83/1000 [00:35<06:23,  2.39it/s]  8%|▊         | 84/1000 [00:35<06:27,  2.37it/s]  8%|▊         | 85/1000 [00:36<06:18,  2.42it/s]  9%|▊         | 86/1000 [00:36<06:13,  2.44it/s]  9%|▊         | 87/1000 [00:36<05:58,  2.55it/s]  9%|▉         | 88/1000 [00:37<05:49,  2.61it/s]  9%|▉         | 89/1000 [00:37<06:05,  2.49it/s]  9%|▉         | 90/1000 [00:38<06:03,  2.51it/s]                                                   9%|▉         | 90/1000 [00:38<06:03,  2.51it/s]  9%|▉         | 91/1000 [00:38<05:52,  2.58it/s]  9%|▉         | 92/1000 [00:38<05:31,  2.74it/s]  9%|▉         | 93/1000 [00:39<05:49,  2.60it/s]  9%|▉         | 94/1000 [00:39<05:48,  2.60it/s] 10%|▉         | 95/1000 [00:39<05:39,  2.66it/s] 10%|▉         | 96/1000 [00:40<05:36,  2.68it/s] 10%|▉         | 97/1000 [00:40<05:53,  2.55it/s] 10%|▉         | 98/1000 [00:41<06:05,  2.47it/s] 10%|▉         | 99/1000 [00:41<05:54,  2.55it/s] 10%|█         | 100/1000 [00:41<05:45,  2.60it/s]                                                   10%|█         | 100/1000 [00:41<05:45,  2.60it/s]Saving model checkpoint to ./output/checkpoint-100
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 10%|█         | 101/1000 [00:42<06:05,  2.46it/s] 10%|█         | 102/1000 [00:42<06:02,  2.48it/s] 10%|█         | 103/1000 [00:43<05:58,  2.50it/s] 10%|█         | 104/1000 [00:43<05:57,  2.50it/s] 10%|█         | 105/1000 [00:44<06:40,  2.24it/s] 11%|█         | 106/1000 [00:44<06:17,  2.37it/s] 11%|█         | 107/1000 [00:44<05:57,  2.50it/s] 11%|█         | 108/1000 [00:45<05:57,  2.49it/s] 11%|█         | 109/1000 [00:45<05:57,  2.49it/s] 11%|█         | 110/1000 [00:45<05:55,  2.50it/s]                                                   11%|█         | 110/1000 [00:45<05:55,  2.50it/s] 11%|█         | 111/1000 [00:46<06:04,  2.44it/s] 11%|█         | 112/1000 [00:46<05:51,  2.53it/s] 11%|█▏        | 113/1000 [00:47<05:52,  2.52it/s] 11%|█▏        | 114/1000 [00:47<05:51,  2.52it/s] 12%|█▏        | 115/1000 [00:47<05:41,  2.59it/s] 12%|█▏        | 116/1000 [00:48<05:42,  2.58it/s] 12%|█▏        | 117/1000 [00:48<05:18,  2.77it/s] 12%|█▏        | 118/1000 [00:48<05:16,  2.79it/s] 12%|█▏        | 119/1000 [00:49<05:37,  2.61it/s] 12%|█▏        | 120/1000 [00:49<05:29,  2.67it/s]                                                   12%|█▏        | 120/1000 [00:49<05:29,  2.67it/s] 12%|█▏        | 121/1000 [00:50<05:28,  2.68it/s] 12%|█▏        | 122/1000 [00:50<05:32,  2.64it/s] 12%|█▏        | 123/1000 [00:50<05:37,  2.60it/s] 12%|█▏        | 124/1000 [00:51<05:40,  2.58it/s] 12%|█▎        | 125/1000 [00:51<05:42,  2.55it/s] 13%|█▎        | 126/1000 [00:52<05:43,  2.54it/s] 13%|█▎        | 127/1000 [00:52<05:55,  2.45it/s] 13%|█▎        | 128/1000 [00:52<06:03,  2.40it/s] 13%|█▎        | 129/1000 [00:53<06:30,  2.23it/s] 13%|█▎        | 130/1000 [00:53<06:17,  2.31it/s]                                                   13%|█▎        | 130/1000 [00:53<06:17,  2.31it/s] 13%|█▎        | 131/1000 [00:54<06:07,  2.37it/s] 13%|█▎        | 132/1000 [00:54<05:58,  2.42it/s] 13%|█▎        | 133/1000 [00:55<05:43,  2.53it/s] 13%|█▎        | 134/1000 [00:55<05:42,  2.53it/s] 14%|█▎        | 135/1000 [00:55<05:52,  2.46it/s] 14%|█▎        | 136/1000 [00:56<05:39,  2.54it/s] 14%|█▎        | 137/1000 [00:56<05:39,  2.54it/s] 14%|█▍        | 138/1000 [00:56<05:31,  2.60it/s] 14%|█▍        | 139/1000 [00:57<05:32,  2.59it/s] 14%|█▍        | 140/1000 [00:57<05:34,  2.57it/s]                                                   14%|█▍        | 140/1000 [00:57<05:34,  2.57it/s] 14%|█▍        | 141/1000 [00:58<05:14,  2.73it/s] 14%|█▍        | 142/1000 [00:58<05:32,  2.58it/s] 14%|█▍        | 143/1000 [00:58<05:32,  2.57it/s] 14%|█▍        | 144/1000 [00:59<05:35,  2.55it/s] 14%|█▍        | 145/1000 [00:59<05:27,  2.61it/s] 15%|█▍        | 146/1000 [01:00<05:30,  2.58it/s] 15%|█▍        | 147/1000 [01:00<05:42,  2.49it/s] 15%|█▍        | 148/1000 [01:00<05:50,  2.43it/s] 15%|█▍        | 149/1000 [01:01<05:46,  2.46it/s] 15%|█▌        | 150/1000 [01:01<05:32,  2.56it/s]                                                   15%|█▌        | 150/1000 [01:01<05:32,  2.56it/s]Saving model checkpoint to ./output/checkpoint-150
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 15%|█▌        | 151/1000 [01:02<06:00,  2.35it/s] 15%|█▌        | 152/1000 [01:02<05:51,  2.41it/s] 15%|█▌        | 153/1000 [01:02<05:36,  2.52it/s] 15%|█▌        | 154/1000 [01:03<05:36,  2.51it/s] 16%|█▌        | 155/1000 [01:03<05:36,  2.51it/s] 16%|█▌        | 156/1000 [01:04<05:45,  2.45it/s] 16%|█▌        | 157/1000 [01:04<05:51,  2.40it/s] 16%|█▌        | 158/1000 [01:04<05:35,  2.51it/s] 16%|█▌        | 159/1000 [01:05<05:34,  2.51it/s] 16%|█▌        | 160/1000 [01:05<05:35,  2.51it/s]                                                   16%|█▌        | 160/1000 [01:05<05:35,  2.51it/s] 16%|█▌        | 161/1000 [01:06<05:44,  2.43it/s] 16%|█▌        | 162/1000 [01:06<05:50,  2.39it/s] 16%|█▋        | 163/1000 [01:07<05:54,  2.36it/s] 16%|█▋        | 164/1000 [01:07<05:55,  2.35it/s] 16%|█▋        | 165/1000 [01:07<05:56,  2.34it/s] 17%|█▋        | 166/1000 [01:08<05:46,  2.41it/s] 17%|█▋        | 167/1000 [01:08<05:49,  2.38it/s] 17%|█▋        | 168/1000 [01:09<05:43,  2.42it/s] 17%|█▋        | 169/1000 [01:09<05:37,  2.46it/s] 17%|█▋        | 170/1000 [01:09<05:34,  2.48it/s]                                                   17%|█▋        | 170/1000 [01:09<05:34,  2.48it/s] 17%|█▋        | 171/1000 [01:10<05:25,  2.54it/s] 17%|█▋        | 172/1000 [01:10<05:27,  2.53it/s] 17%|█▋        | 173/1000 [01:11<05:52,  2.34it/s] 17%|█▋        | 174/1000 [01:11<05:45,  2.39it/s] 18%|█▊        | 175/1000 [01:12<05:40,  2.43it/s] 18%|█▊        | 176/1000 [01:12<05:36,  2.45it/s] 18%|█▊        | 177/1000 [01:12<05:43,  2.40it/s] 18%|█▊        | 178/1000 [01:13<05:37,  2.44it/s] 18%|█▊        | 179/1000 [01:13<05:33,  2.46it/s] 18%|█▊        | 180/1000 [01:14<05:22,  2.54it/s]                                                   18%|█▊        | 180/1000 [01:14<05:22,  2.54it/s] 18%|█▊        | 181/1000 [01:14<05:31,  2.47it/s] 18%|█▊        | 182/1000 [01:14<05:28,  2.49it/s] 18%|█▊        | 183/1000 [01:15<05:27,  2.49it/s] 18%|█▊        | 184/1000 [01:15<05:26,  2.50it/s] 18%|█▊        | 185/1000 [01:15<05:16,  2.57it/s] 19%|█▊        | 186/1000 [01:16<05:18,  2.56it/s] 19%|█▊        | 187/1000 [01:16<05:27,  2.48it/s] 19%|█▉        | 188/1000 [01:17<05:25,  2.49it/s] 19%|█▉        | 189/1000 [01:17<05:24,  2.50it/s] 19%|█▉        | 190/1000 [01:18<05:23,  2.50it/s]                                                   19%|█▉        | 190/1000 [01:18<05:23,  2.50it/s] 19%|█▉        | 191/1000 [01:18<05:31,  2.44it/s] 19%|█▉        | 192/1000 [01:18<05:36,  2.40it/s] 19%|█▉        | 193/1000 [01:19<05:31,  2.43it/s] 19%|█▉        | 194/1000 [01:19<05:19,  2.53it/s] 20%|█▉        | 195/1000 [01:20<05:11,  2.58it/s] 20%|█▉        | 196/1000 [01:20<05:23,  2.49it/s] 20%|█▉        | 197/1000 [01:20<05:22,  2.49it/s] 20%|█▉        | 198/1000 [01:21<05:30,  2.43it/s] 20%|█▉        | 199/1000 [01:21<05:59,  2.23it/s] 20%|██        | 200/1000 [01:22<05:54,  2.25it/s]                                                   20%|██        | 200/1000 [01:22<05:54,  2.25it/s]Saving model checkpoint to ./output/checkpoint-200
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 20%|██        | 201/1000 [01:22<06:06,  2.18it/s] 20%|██        | 202/1000 [01:23<06:00,  2.21it/s] 20%|██        | 203/1000 [01:23<05:47,  2.30it/s] 20%|██        | 204/1000 [01:23<05:38,  2.35it/s] 20%|██        | 205/1000 [01:24<05:30,  2.41it/s] 21%|██        | 206/1000 [01:24<05:24,  2.45it/s] 21%|██        | 207/1000 [01:25<05:30,  2.40it/s] 21%|██        | 208/1000 [01:25<05:33,  2.37it/s] 21%|██        | 209/1000 [01:26<05:24,  2.43it/s] 21%|██        | 210/1000 [01:26<05:21,  2.46it/s]                                                   21%|██        | 210/1000 [01:26<05:21,  2.46it/s] 21%|██        | 211/1000 [01:26<05:16,  2.50it/s] 21%|██        | 212/1000 [01:27<04:54,  2.68it/s] 21%|██▏       | 213/1000 [01:27<04:58,  2.64it/s] 21%|██▏       | 214/1000 [01:27<05:10,  2.53it/s] 22%|██▏       | 215/1000 [01:28<05:07,  2.55it/s] 22%|██▏       | 216/1000 [01:28<05:08,  2.54it/s] 22%|██▏       | 217/1000 [01:29<05:09,  2.53it/s] 22%|██▏       | 218/1000 [01:29<05:17,  2.46it/s] 22%|██▏       | 219/1000 [01:29<05:06,  2.55it/s] 22%|██▏       | 220/1000 [01:30<05:07,  2.53it/s]                                                   22%|██▏       | 220/1000 [01:30<05:07,  2.53it/s] 22%|██▏       | 221/1000 [01:30<05:15,  2.47it/s] 22%|██▏       | 222/1000 [01:31<05:14,  2.47it/s] 22%|██▏       | 223/1000 [01:31<05:40,  2.28it/s] 22%|██▏       | 224/1000 [01:32<05:38,  2.30it/s] 22%|██▎       | 225/1000 [01:32<05:21,  2.41it/s] 23%|██▎       | 226/1000 [01:32<05:16,  2.45it/s] 23%|██▎       | 227/1000 [01:33<05:03,  2.55it/s] 23%|██▎       | 228/1000 [01:33<04:55,  2.61it/s] 23%|██▎       | 229/1000 [01:33<04:58,  2.58it/s] 23%|██▎       | 230/1000 [01:34<04:53,  2.62it/s]                                                   23%|██▎       | 230/1000 [01:34<04:53,  2.62it/s] 23%|██▎       | 231/1000 [01:34<04:57,  2.59it/s] 23%|██▎       | 232/1000 [01:35<04:57,  2.58it/s] 23%|██▎       | 233/1000 [01:35<04:59,  2.56it/s] 23%|██▎       | 234/1000 [01:35<04:50,  2.63it/s] 24%|██▎       | 235/1000 [01:36<04:56,  2.58it/s] 24%|██▎       | 236/1000 [01:36<04:59,  2.55it/s] 24%|██▎       | 237/1000 [01:37<05:02,  2.52it/s] 24%|██▍       | 238/1000 [01:37<05:00,  2.53it/s] 24%|██▍       | 239/1000 [01:37<05:09,  2.46it/s] 24%|██▍       | 240/1000 [01:38<05:07,  2.47it/s]                                                   24%|██▍       | 240/1000 [01:38<05:07,  2.47it/s] 24%|██▍       | 241/1000 [01:38<05:05,  2.49it/s] 24%|██▍       | 242/1000 [01:39<04:53,  2.58it/s] 24%|██▍       | 243/1000 [01:39<04:55,  2.56it/s] 24%|██▍       | 244/1000 [01:39<05:05,  2.48it/s] 24%|██▍       | 245/1000 [01:40<05:37,  2.24it/s] 25%|██▍       | 246/1000 [01:40<05:24,  2.32it/s] 25%|██▍       | 247/1000 [01:41<05:09,  2.43it/s] 25%|██▍       | 248/1000 [01:41<05:05,  2.47it/s] 25%|██▍       | 249/1000 [01:41<05:02,  2.49it/s] 25%|██▌       | 250/1000 [01:42<05:00,  2.50it/s]                                                   25%|██▌       | 250/1000 [01:42<05:00,  2.50it/s]Saving model checkpoint to ./output/checkpoint-250
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 25%|██▌       | 251/1000 [01:42<05:20,  2.33it/s] 25%|██▌       | 252/1000 [01:43<05:20,  2.33it/s] 25%|██▌       | 253/1000 [01:43<05:03,  2.46it/s] 25%|██▌       | 254/1000 [01:44<05:09,  2.41it/s] 26%|██▌       | 255/1000 [01:44<05:13,  2.37it/s] 26%|██▌       | 256/1000 [01:44<04:58,  2.49it/s] 26%|██▌       | 257/1000 [01:45<04:47,  2.58it/s] 26%|██▌       | 258/1000 [01:45<04:40,  2.65it/s] 26%|██▌       | 259/1000 [01:46<04:52,  2.54it/s] 26%|██▌       | 260/1000 [01:46<04:53,  2.52it/s]                                                   26%|██▌       | 260/1000 [01:46<04:53,  2.52it/s] 26%|██▌       | 261/1000 [01:46<04:59,  2.46it/s] 26%|██▌       | 262/1000 [01:47<05:04,  2.42it/s] 26%|██▋       | 263/1000 [01:47<04:59,  2.46it/s] 26%|██▋       | 264/1000 [01:48<04:56,  2.48it/s] 26%|██▋       | 265/1000 [01:48<04:45,  2.58it/s] 27%|██▋       | 266/1000 [01:48<04:55,  2.48it/s] 27%|██▋       | 267/1000 [01:49<04:52,  2.50it/s] 27%|██▋       | 268/1000 [01:49<05:21,  2.27it/s] 27%|██▋       | 269/1000 [01:50<05:12,  2.34it/s] 27%|██▋       | 270/1000 [01:50<05:06,  2.38it/s]                                                   27%|██▋       | 270/1000 [01:50<05:06,  2.38it/s] 27%|██▋       | 271/1000 [01:51<05:08,  2.36it/s] 27%|██▋       | 272/1000 [01:51<05:01,  2.41it/s] 27%|██▋       | 273/1000 [01:51<04:57,  2.44it/s] 27%|██▋       | 274/1000 [01:52<04:47,  2.53it/s] 28%|██▊       | 275/1000 [01:52<04:47,  2.52it/s] 28%|██▊       | 276/1000 [01:52<04:46,  2.53it/s] 28%|██▊       | 277/1000 [01:53<04:36,  2.61it/s] 28%|██▊       | 278/1000 [01:53<04:31,  2.66it/s] 28%|██▊       | 279/1000 [01:54<04:44,  2.54it/s] 28%|██▊       | 280/1000 [01:54<04:42,  2.54it/s]                                                   28%|██▊       | 280/1000 [01:54<04:42,  2.54it/s] 28%|██▊       | 281/1000 [01:54<04:51,  2.47it/s] 28%|██▊       | 282/1000 [01:55<04:56,  2.42it/s] 28%|██▊       | 283/1000 [01:55<05:00,  2.39it/s] 28%|██▊       | 284/1000 [01:56<04:54,  2.43it/s] 28%|██▊       | 285/1000 [01:56<04:50,  2.46it/s] 29%|██▊       | 286/1000 [01:56<04:47,  2.49it/s] 29%|██▊       | 287/1000 [01:57<04:44,  2.51it/s] 29%|██▉       | 288/1000 [01:57<04:44,  2.51it/s] 29%|██▉       | 289/1000 [01:58<04:34,  2.59it/s] 29%|██▉       | 290/1000 [01:58<04:26,  2.66it/s]                                                   29%|██▉       | 290/1000 [01:58<04:26,  2.66it/s] 29%|██▉       | 291/1000 [01:58<04:31,  2.61it/s] 29%|██▉       | 292/1000 [01:59<04:42,  2.51it/s] 29%|██▉       | 293/1000 [01:59<04:41,  2.52it/s] 29%|██▉       | 294/1000 [02:00<05:06,  2.30it/s] 30%|██▉       | 295/1000 [02:00<04:56,  2.38it/s] 30%|██▉       | 296/1000 [02:01<04:50,  2.42it/s] 30%|██▉       | 297/1000 [02:01<04:46,  2.46it/s] 30%|██▉       | 298/1000 [02:01<04:44,  2.47it/s] 30%|██▉       | 299/1000 [02:02<04:42,  2.48it/s] 30%|███       | 300/1000 [02:02<04:22,  2.66it/s]                                                   30%|███       | 300/1000 [02:02<04:22,  2.66it/s]Saving model checkpoint to ./output/checkpoint-300
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 30%|███       | 301/1000 [02:02<04:39,  2.50it/s] 30%|███       | 302/1000 [02:03<04:39,  2.50it/s] 30%|███       | 303/1000 [02:03<04:36,  2.52it/s] 30%|███       | 304/1000 [02:04<04:37,  2.51it/s] 30%|███       | 305/1000 [02:04<04:34,  2.53it/s] 31%|███       | 306/1000 [02:04<04:42,  2.45it/s] 31%|███       | 307/1000 [02:05<04:31,  2.55it/s] 31%|███       | 308/1000 [02:05<04:25,  2.60it/s] 31%|███       | 309/1000 [02:06<04:36,  2.50it/s] 31%|███       | 310/1000 [02:06<04:36,  2.50it/s]                                                   31%|███       | 310/1000 [02:06<04:36,  2.50it/s] 31%|███       | 311/1000 [02:06<04:31,  2.54it/s] 31%|███       | 312/1000 [02:07<04:33,  2.51it/s] 31%|███▏      | 313/1000 [02:07<04:29,  2.55it/s] 31%|███▏      | 314/1000 [02:08<04:37,  2.47it/s] 32%|███▏      | 315/1000 [02:08<04:35,  2.48it/s] 32%|███▏      | 316/1000 [02:08<04:32,  2.51it/s] 32%|███▏      | 317/1000 [02:09<04:49,  2.36it/s] 32%|███▏      | 318/1000 [02:09<04:50,  2.34it/s] 32%|███▏      | 319/1000 [02:10<04:51,  2.34it/s] 32%|███▏      | 320/1000 [02:10<04:46,  2.38it/s]                                                   32%|███▏      | 320/1000 [02:10<04:46,  2.38it/s] 32%|███▏      | 321/1000 [02:11<04:40,  2.42it/s] 32%|███▏      | 322/1000 [02:11<04:37,  2.45it/s] 32%|███▏      | 323/1000 [02:11<04:34,  2.46it/s] 32%|███▏      | 324/1000 [02:12<04:32,  2.48it/s] 32%|███▎      | 325/1000 [02:12<04:31,  2.49it/s] 33%|███▎      | 326/1000 [02:13<04:39,  2.41it/s] 33%|███▎      | 327/1000 [02:13<04:36,  2.44it/s] 33%|███▎      | 328/1000 [02:13<04:33,  2.46it/s] 33%|███▎      | 329/1000 [02:14<04:31,  2.47it/s] 33%|███▎      | 330/1000 [02:14<04:29,  2.48it/s]                                                   33%|███▎      | 330/1000 [02:14<04:29,  2.48it/s] 33%|███▎      | 331/1000 [02:15<04:35,  2.43it/s] 33%|███▎      | 332/1000 [02:15<04:39,  2.39it/s] 33%|███▎      | 333/1000 [02:16<04:42,  2.36it/s] 33%|███▎      | 334/1000 [02:16<04:31,  2.45it/s] 34%|███▎      | 335/1000 [02:16<04:27,  2.48it/s] 34%|███▎      | 336/1000 [02:17<04:26,  2.49it/s] 34%|███▎      | 337/1000 [02:17<04:24,  2.50it/s] 34%|███▍      | 338/1000 [02:17<04:24,  2.50it/s] 34%|███▍      | 339/1000 [02:18<04:45,  2.32it/s] 34%|███▍      | 340/1000 [02:18<04:36,  2.38it/s]                                                   34%|███▍      | 340/1000 [02:18<04:36,  2.38it/s] 34%|███▍      | 341/1000 [02:19<04:14,  2.59it/s] 34%|███▍      | 342/1000 [02:19<04:16,  2.57it/s] 34%|███▍      | 343/1000 [02:19<04:09,  2.63it/s] 34%|███▍      | 344/1000 [02:20<04:12,  2.60it/s] 34%|███▍      | 345/1000 [02:20<04:05,  2.67it/s] 35%|███▍      | 346/1000 [02:21<04:08,  2.63it/s] 35%|███▍      | 347/1000 [02:21<04:10,  2.61it/s] 35%|███▍      | 348/1000 [02:21<04:12,  2.58it/s] 35%|███▍      | 349/1000 [02:22<04:14,  2.56it/s] 35%|███▌      | 350/1000 [02:22<04:08,  2.62it/s]                                                   35%|███▌      | 350/1000 [02:22<04:08,  2.62it/s]Saving model checkpoint to ./output/checkpoint-350
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 35%|███▌      | 351/1000 [02:23<04:19,  2.50it/s] 35%|███▌      | 352/1000 [02:23<04:25,  2.44it/s] 35%|███▌      | 353/1000 [02:23<04:21,  2.47it/s] 35%|███▌      | 354/1000 [02:24<04:18,  2.50it/s] 36%|███▌      | 355/1000 [02:24<04:16,  2.52it/s] 36%|███▌      | 356/1000 [02:25<04:14,  2.53it/s] 36%|███▌      | 357/1000 [02:25<04:14,  2.53it/s] 36%|███▌      | 358/1000 [02:25<04:08,  2.58it/s] 36%|███▌      | 359/1000 [02:26<04:03,  2.63it/s] 36%|███▌      | 360/1000 [02:26<04:06,  2.60it/s]                                                   36%|███▌      | 360/1000 [02:26<04:06,  2.60it/s] 36%|███▌      | 361/1000 [02:27<04:16,  2.49it/s] 36%|███▌      | 362/1000 [02:27<04:09,  2.56it/s] 36%|███▋      | 363/1000 [02:27<04:39,  2.28it/s] 36%|███▋      | 364/1000 [02:28<04:37,  2.29it/s] 36%|███▋      | 365/1000 [02:28<04:35,  2.30it/s] 37%|███▋      | 366/1000 [02:29<04:27,  2.37it/s] 37%|███▋      | 367/1000 [02:29<04:15,  2.48it/s] 37%|███▋      | 368/1000 [02:29<04:09,  2.54it/s] 37%|███▋      | 369/1000 [02:30<04:09,  2.53it/s] 37%|███▋      | 370/1000 [02:30<04:04,  2.57it/s]                                                   37%|███▋      | 370/1000 [02:30<04:04,  2.57it/s] 37%|███▋      | 371/1000 [02:31<04:06,  2.55it/s] 37%|███▋      | 372/1000 [02:31<04:08,  2.53it/s] 37%|███▋      | 373/1000 [02:31<04:14,  2.46it/s] 37%|███▋      | 374/1000 [02:32<04:12,  2.48it/s] 38%|███▊      | 375/1000 [02:32<04:12,  2.48it/s] 38%|███▊      | 376/1000 [02:33<04:11,  2.48it/s] 38%|███▊      | 377/1000 [02:33<04:04,  2.55it/s] 38%|███▊      | 378/1000 [02:33<04:00,  2.58it/s] 38%|███▊      | 379/1000 [02:34<04:13,  2.45it/s] 38%|███▊      | 380/1000 [02:34<04:19,  2.39it/s]                                                   38%|███▊      | 380/1000 [02:34<04:19,  2.39it/s] 38%|███▊      | 381/1000 [02:35<04:16,  2.41it/s] 38%|███▊      | 382/1000 [02:35<04:23,  2.34it/s] 38%|███▊      | 383/1000 [02:36<04:18,  2.39it/s] 38%|███▊      | 384/1000 [02:36<04:24,  2.33it/s] 38%|███▊      | 385/1000 [02:36<04:20,  2.36it/s] 39%|███▊      | 386/1000 [02:37<04:16,  2.39it/s] 39%|███▊      | 387/1000 [02:37<04:14,  2.41it/s] 39%|███▉      | 388/1000 [02:38<04:18,  2.37it/s] 39%|███▉      | 389/1000 [02:38<04:40,  2.18it/s] 39%|███▉      | 390/1000 [02:39<04:31,  2.24it/s]                                                   39%|███▉      | 390/1000 [02:39<04:31,  2.24it/s] 39%|███▉      | 391/1000 [02:39<04:21,  2.33it/s] 39%|███▉      | 392/1000 [02:39<04:23,  2.31it/s] 39%|███▉      | 393/1000 [02:40<04:15,  2.38it/s] 39%|███▉      | 394/1000 [02:40<04:03,  2.49it/s] 40%|███▉      | 395/1000 [02:41<04:00,  2.52it/s] 40%|███▉      | 396/1000 [02:41<04:05,  2.46it/s] 40%|███▉      | 397/1000 [02:41<03:56,  2.55it/s] 40%|███▉      | 398/1000 [02:42<03:57,  2.53it/s] 40%|███▉      | 399/1000 [02:42<03:52,  2.58it/s] 40%|████      | 400/1000 [02:43<04:01,  2.49it/s]                                                   40%|████      | 400/1000 [02:43<04:01,  2.49it/s]Saving model checkpoint to ./output/checkpoint-400
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 40%|████      | 401/1000 [02:43<04:10,  2.39it/s] 40%|████      | 402/1000 [02:43<04:00,  2.49it/s] 40%|████      | 403/1000 [02:44<03:59,  2.49it/s] 40%|████      | 404/1000 [02:44<03:57,  2.51it/s] 40%|████      | 405/1000 [02:45<03:57,  2.50it/s] 41%|████      | 406/1000 [02:45<03:58,  2.49it/s] 41%|████      | 407/1000 [02:45<03:58,  2.49it/s] 41%|████      | 408/1000 [02:46<04:03,  2.43it/s] 41%|████      | 409/1000 [02:46<04:02,  2.44it/s] 41%|████      | 410/1000 [02:47<04:01,  2.45it/s]                                                   41%|████      | 410/1000 [02:47<04:01,  2.45it/s] 41%|████      | 411/1000 [02:47<04:00,  2.45it/s] 41%|████      | 412/1000 [02:47<04:00,  2.45it/s] 41%|████▏     | 413/1000 [02:48<04:24,  2.22it/s] 41%|████▏     | 414/1000 [02:48<04:12,  2.32it/s] 42%|████▏     | 415/1000 [02:49<04:04,  2.39it/s] 42%|████▏     | 416/1000 [02:49<04:00,  2.43it/s] 42%|████▏     | 417/1000 [02:50<03:57,  2.45it/s] 42%|████▏     | 418/1000 [02:50<03:49,  2.54it/s] 42%|████▏     | 419/1000 [02:50<03:55,  2.47it/s] 42%|████▏     | 420/1000 [02:51<03:52,  2.49it/s]                                                   42%|████▏     | 420/1000 [02:51<03:52,  2.49it/s] 42%|████▏     | 421/1000 [02:51<03:51,  2.50it/s] 42%|████▏     | 422/1000 [02:52<03:44,  2.58it/s] 42%|████▏     | 423/1000 [02:52<03:43,  2.58it/s] 42%|████▏     | 424/1000 [02:52<03:45,  2.55it/s] 42%|████▎     | 425/1000 [02:53<03:52,  2.47it/s] 43%|████▎     | 426/1000 [02:53<03:56,  2.42it/s] 43%|████▎     | 427/1000 [02:54<03:53,  2.45it/s] 43%|████▎     | 428/1000 [02:54<03:59,  2.39it/s] 43%|████▎     | 429/1000 [02:54<04:00,  2.37it/s] 43%|████▎     | 430/1000 [02:55<03:54,  2.43it/s]                                                   43%|████▎     | 430/1000 [02:55<03:54,  2.43it/s] 43%|████▎     | 431/1000 [02:55<03:51,  2.45it/s] 43%|████▎     | 432/1000 [02:56<03:56,  2.41it/s] 43%|████▎     | 433/1000 [02:56<03:44,  2.52it/s] 43%|████▎     | 434/1000 [02:56<03:43,  2.53it/s] 44%|████▎     | 435/1000 [02:57<04:01,  2.34it/s] 44%|████▎     | 436/1000 [02:57<03:56,  2.39it/s] 44%|████▎     | 437/1000 [02:58<03:52,  2.42it/s] 44%|████▍     | 438/1000 [02:58<03:42,  2.52it/s] 44%|████▍     | 439/1000 [02:58<03:42,  2.52it/s] 44%|████▍     | 440/1000 [02:59<03:41,  2.52it/s]                                                   44%|████▍     | 440/1000 [02:59<03:41,  2.52it/s] 44%|████▍     | 441/1000 [02:59<03:26,  2.70it/s] 44%|████▍     | 442/1000 [03:00<03:31,  2.64it/s] 44%|████▍     | 443/1000 [03:00<03:32,  2.62it/s] 44%|████▍     | 444/1000 [03:00<03:33,  2.61it/s] 44%|████▍     | 445/1000 [03:01<03:33,  2.60it/s] 45%|████▍     | 446/1000 [03:01<03:35,  2.57it/s] 45%|████▍     | 447/1000 [03:02<03:43,  2.47it/s] 45%|████▍     | 448/1000 [03:02<03:42,  2.48it/s] 45%|████▍     | 449/1000 [03:02<03:34,  2.57it/s] 45%|████▌     | 450/1000 [03:03<03:35,  2.56it/s]                                                   45%|████▌     | 450/1000 [03:03<03:35,  2.56it/s]Saving model checkpoint to ./output/checkpoint-450
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 45%|████▌     | 451/1000 [03:03<03:54,  2.34it/s] 45%|████▌     | 452/1000 [03:04<03:54,  2.33it/s] 45%|████▌     | 453/1000 [03:04<03:43,  2.45it/s] 45%|████▌     | 454/1000 [03:04<03:42,  2.46it/s] 46%|████▌     | 455/1000 [03:05<03:34,  2.54it/s] 46%|████▌     | 456/1000 [03:05<03:41,  2.46it/s] 46%|████▌     | 457/1000 [03:06<03:33,  2.55it/s] 46%|████▌     | 458/1000 [03:06<03:39,  2.47it/s] 46%|████▌     | 459/1000 [03:06<03:37,  2.48it/s] 46%|████▌     | 460/1000 [03:07<03:36,  2.49it/s]                                                   46%|████▌     | 460/1000 [03:07<03:36,  2.49it/s] 46%|████▌     | 461/1000 [03:07<03:56,  2.28it/s] 46%|████▌     | 462/1000 [03:08<03:44,  2.40it/s] 46%|████▋     | 463/1000 [03:08<03:39,  2.45it/s] 46%|████▋     | 464/1000 [03:09<03:38,  2.46it/s] 46%|████▋     | 465/1000 [03:09<03:36,  2.47it/s] 47%|████▋     | 466/1000 [03:09<03:34,  2.49it/s] 47%|████▋     | 467/1000 [03:10<03:25,  2.59it/s] 47%|████▋     | 468/1000 [03:10<03:32,  2.50it/s] 47%|████▋     | 469/1000 [03:10<03:31,  2.51it/s] 47%|████▋     | 470/1000 [03:11<03:31,  2.51it/s]                                                   47%|████▋     | 470/1000 [03:11<03:31,  2.51it/s] 47%|████▋     | 471/1000 [03:11<03:24,  2.58it/s] 47%|████▋     | 472/1000 [03:12<03:25,  2.56it/s] 47%|████▋     | 473/1000 [03:12<03:26,  2.55it/s] 47%|████▋     | 474/1000 [03:12<03:22,  2.60it/s] 48%|████▊     | 475/1000 [03:13<03:29,  2.50it/s] 48%|████▊     | 476/1000 [03:13<03:28,  2.51it/s] 48%|████▊     | 477/1000 [03:14<03:28,  2.51it/s] 48%|████▊     | 478/1000 [03:14<03:27,  2.51it/s] 48%|████▊     | 479/1000 [03:14<03:27,  2.52it/s] 48%|████▊     | 480/1000 [03:15<03:26,  2.52it/s]                                                   48%|████▊     | 480/1000 [03:15<03:26,  2.52it/s] 48%|████▊     | 481/1000 [03:15<03:25,  2.53it/s] 48%|████▊     | 482/1000 [03:16<03:30,  2.46it/s] 48%|████▊     | 483/1000 [03:16<03:29,  2.47it/s] 48%|████▊     | 484/1000 [03:16<03:26,  2.50it/s] 48%|████▊     | 485/1000 [03:17<03:40,  2.34it/s] 49%|████▊     | 486/1000 [03:17<03:34,  2.39it/s] 49%|████▊     | 487/1000 [03:18<03:30,  2.44it/s] 49%|████▉     | 488/1000 [03:18<03:33,  2.40it/s] 49%|████▉     | 489/1000 [03:19<03:35,  2.37it/s] 49%|████▉     | 490/1000 [03:19<03:36,  2.35it/s]                                                   49%|████▉     | 490/1000 [03:19<03:36,  2.35it/s] 49%|████▉     | 491/1000 [03:19<03:37,  2.34it/s] 49%|████▉     | 492/1000 [03:20<03:26,  2.46it/s] 49%|████▉     | 493/1000 [03:20<03:10,  2.65it/s] 49%|████▉     | 494/1000 [03:21<03:19,  2.54it/s] 50%|████▉     | 495/1000 [03:21<03:17,  2.55it/s] 50%|████▉     | 496/1000 [03:21<03:18,  2.54it/s] 50%|████▉     | 497/1000 [03:22<03:11,  2.63it/s] 50%|████▉     | 498/1000 [03:22<03:19,  2.52it/s] 50%|████▉     | 499/1000 [03:22<03:18,  2.52it/s] 50%|█████     | 500/1000 [03:23<03:18,  2.52it/s]                                                   50%|█████     | 500/1000 [03:23<03:18,  2.52it/s]Saving model checkpoint to ./output/checkpoint-500
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 50%|█████     | 501/1000 [03:23<03:34,  2.32it/s] 50%|█████     | 502/1000 [03:24<03:23,  2.45it/s] 50%|█████     | 503/1000 [03:24<03:17,  2.52it/s] 50%|█████     | 504/1000 [03:25<03:17,  2.52it/s] 50%|█████     | 505/1000 [03:25<03:22,  2.44it/s] 51%|█████     | 506/1000 [03:25<03:21,  2.46it/s] 51%|█████     | 507/1000 [03:26<03:19,  2.48it/s] 51%|█████     | 508/1000 [03:26<03:40,  2.24it/s] 51%|█████     | 509/1000 [03:27<03:31,  2.33it/s] 51%|█████     | 510/1000 [03:27<03:30,  2.32it/s]                                                   51%|█████     | 510/1000 [03:27<03:30,  2.32it/s] 51%|█████     | 511/1000 [03:28<03:30,  2.32it/s] 51%|█████     | 512/1000 [03:28<03:25,  2.37it/s] 51%|█████▏    | 513/1000 [03:28<03:20,  2.43it/s] 51%|█████▏    | 514/1000 [03:29<03:17,  2.46it/s] 52%|█████▏    | 515/1000 [03:29<03:16,  2.47it/s] 52%|█████▏    | 516/1000 [03:30<03:19,  2.42it/s] 52%|█████▏    | 517/1000 [03:30<03:16,  2.46it/s] 52%|█████▏    | 518/1000 [03:30<03:14,  2.48it/s] 52%|█████▏    | 519/1000 [03:31<03:13,  2.49it/s] 52%|█████▏    | 520/1000 [03:31<03:11,  2.50it/s]                                                   52%|█████▏    | 520/1000 [03:31<03:11,  2.50it/s] 52%|█████▏    | 521/1000 [03:32<03:11,  2.50it/s] 52%|█████▏    | 522/1000 [03:32<03:10,  2.51it/s] 52%|█████▏    | 523/1000 [03:32<03:03,  2.60it/s] 52%|█████▏    | 524/1000 [03:33<02:58,  2.66it/s] 52%|█████▎    | 525/1000 [03:33<03:00,  2.64it/s] 53%|█████▎    | 526/1000 [03:33<03:03,  2.59it/s] 53%|█████▎    | 527/1000 [03:34<03:10,  2.48it/s] 53%|█████▎    | 528/1000 [03:34<03:09,  2.49it/s] 53%|█████▎    | 529/1000 [03:35<03:07,  2.51it/s] 53%|█████▎    | 530/1000 [03:35<03:25,  2.29it/s]                                                   53%|█████▎    | 530/1000 [03:35<03:25,  2.29it/s] 53%|█████▎    | 531/1000 [03:36<03:23,  2.30it/s] 53%|█████▎    | 532/1000 [03:36<03:16,  2.38it/s] 53%|█████▎    | 533/1000 [03:36<03:13,  2.42it/s] 53%|█████▎    | 534/1000 [03:37<03:15,  2.39it/s] 54%|█████▎    | 535/1000 [03:37<03:05,  2.51it/s] 54%|█████▎    | 536/1000 [03:38<03:05,  2.51it/s] 54%|█████▎    | 537/1000 [03:38<03:04,  2.50it/s] 54%|█████▍    | 538/1000 [03:38<03:04,  2.50it/s] 54%|█████▍    | 539/1000 [03:39<02:59,  2.57it/s] 54%|█████▍    | 540/1000 [03:39<03:06,  2.47it/s]                                                   54%|█████▍    | 540/1000 [03:39<03:06,  2.47it/s] 54%|█████▍    | 541/1000 [03:40<03:06,  2.47it/s] 54%|█████▍    | 542/1000 [03:40<03:00,  2.54it/s] 54%|█████▍    | 543/1000 [03:40<02:54,  2.61it/s] 54%|█████▍    | 544/1000 [03:41<02:55,  2.59it/s] 55%|█████▍    | 545/1000 [03:41<03:01,  2.50it/s] 55%|█████▍    | 546/1000 [03:42<03:06,  2.44it/s] 55%|█████▍    | 547/1000 [03:42<03:04,  2.46it/s] 55%|█████▍    | 548/1000 [03:42<03:01,  2.49it/s] 55%|█████▍    | 549/1000 [03:43<03:05,  2.43it/s] 55%|█████▌    | 550/1000 [03:43<03:02,  2.46it/s]                                                   55%|█████▌    | 550/1000 [03:43<03:02,  2.46it/s]Saving model checkpoint to ./output/checkpoint-550
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 55%|█████▌    | 551/1000 [03:44<03:09,  2.36it/s] 55%|█████▌    | 552/1000 [03:44<03:05,  2.41it/s] 55%|█████▌    | 553/1000 [03:44<02:58,  2.51it/s] 55%|█████▌    | 554/1000 [03:45<02:56,  2.52it/s] 56%|█████▌    | 555/1000 [03:45<02:55,  2.53it/s] 56%|█████▌    | 556/1000 [03:46<03:11,  2.31it/s] 56%|█████▌    | 557/1000 [03:46<03:01,  2.44it/s] 56%|█████▌    | 558/1000 [03:46<02:58,  2.48it/s] 56%|█████▌    | 559/1000 [03:47<03:02,  2.41it/s] 56%|█████▌    | 560/1000 [03:47<02:48,  2.61it/s]                                                   56%|█████▌    | 560/1000 [03:47<02:48,  2.61it/s] 56%|█████▌    | 561/1000 [03:48<02:47,  2.63it/s] 56%|█████▌    | 562/1000 [03:48<02:50,  2.57it/s] 56%|█████▋    | 563/1000 [03:48<02:51,  2.54it/s] 56%|█████▋    | 564/1000 [03:49<02:53,  2.51it/s] 56%|█████▋    | 565/1000 [03:49<02:53,  2.50it/s] 57%|█████▋    | 566/1000 [03:50<02:59,  2.42it/s] 57%|█████▋    | 567/1000 [03:50<03:01,  2.38it/s] 57%|█████▋    | 568/1000 [03:51<03:03,  2.35it/s] 57%|█████▋    | 569/1000 [03:51<02:59,  2.40it/s] 57%|█████▋    | 570/1000 [03:51<02:56,  2.44it/s]                                                   57%|█████▋    | 570/1000 [03:51<02:56,  2.44it/s] 57%|█████▋    | 571/1000 [03:52<02:59,  2.39it/s] 57%|█████▋    | 572/1000 [03:52<02:50,  2.51it/s] 57%|█████▋    | 573/1000 [03:53<02:49,  2.52it/s] 57%|█████▋    | 574/1000 [03:53<02:49,  2.52it/s] 57%|█████▊    | 575/1000 [03:53<02:54,  2.44it/s] 58%|█████▊    | 576/1000 [03:54<02:52,  2.45it/s] 58%|█████▊    | 577/1000 [03:54<02:50,  2.48it/s] 58%|█████▊    | 578/1000 [03:55<02:45,  2.55it/s] 58%|█████▊    | 579/1000 [03:55<02:45,  2.55it/s] 58%|█████▊    | 580/1000 [03:55<02:55,  2.40it/s]                                                   58%|█████▊    | 580/1000 [03:55<02:55,  2.40it/s] 58%|█████▊    | 581/1000 [03:56<02:56,  2.37it/s] 58%|█████▊    | 582/1000 [03:56<02:53,  2.41it/s] 58%|█████▊    | 583/1000 [03:57<02:45,  2.53it/s] 58%|█████▊    | 584/1000 [03:57<02:43,  2.54it/s] 58%|█████▊    | 585/1000 [03:57<02:48,  2.47it/s] 59%|█████▊    | 586/1000 [03:58<02:47,  2.48it/s] 59%|█████▊    | 587/1000 [03:58<02:41,  2.56it/s] 59%|█████▉    | 588/1000 [03:59<02:46,  2.48it/s] 59%|█████▉    | 589/1000 [03:59<02:45,  2.48it/s] 59%|█████▉    | 590/1000 [03:59<02:33,  2.67it/s]                                                   59%|█████▉    | 590/1000 [03:59<02:33,  2.67it/s] 59%|█████▉    | 591/1000 [04:00<02:40,  2.55it/s] 59%|█████▉    | 592/1000 [04:00<02:45,  2.47it/s] 59%|█████▉    | 593/1000 [04:01<02:38,  2.56it/s] 59%|█████▉    | 594/1000 [04:01<02:39,  2.54it/s] 60%|█████▉    | 595/1000 [04:01<02:35,  2.60it/s] 60%|█████▉    | 596/1000 [04:02<02:41,  2.50it/s] 60%|█████▉    | 597/1000 [04:02<02:37,  2.56it/s] 60%|█████▉    | 598/1000 [04:02<02:38,  2.54it/s] 60%|█████▉    | 599/1000 [04:03<02:38,  2.54it/s] 60%|██████    | 600/1000 [04:03<02:37,  2.53it/s]                                                   60%|██████    | 600/1000 [04:03<02:37,  2.53it/s]Saving model checkpoint to ./output/checkpoint-600
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 60%|██████    | 601/1000 [04:04<02:41,  2.47it/s] 60%|██████    | 602/1000 [04:04<02:54,  2.27it/s] 60%|██████    | 603/1000 [04:05<02:49,  2.34it/s] 60%|██████    | 604/1000 [04:05<02:45,  2.40it/s] 60%|██████    | 605/1000 [04:05<02:42,  2.43it/s] 61%|██████    | 606/1000 [04:06<02:44,  2.39it/s] 61%|██████    | 607/1000 [04:06<02:46,  2.36it/s] 61%|██████    | 608/1000 [04:07<02:43,  2.40it/s] 61%|██████    | 609/1000 [04:07<02:44,  2.37it/s] 61%|██████    | 610/1000 [04:08<02:41,  2.41it/s]                                                   61%|██████    | 610/1000 [04:08<02:41,  2.41it/s] 61%|██████    | 611/1000 [04:08<02:35,  2.50it/s] 61%|██████    | 612/1000 [04:08<02:34,  2.51it/s] 61%|██████▏   | 613/1000 [04:09<02:33,  2.52it/s] 61%|██████▏   | 614/1000 [04:09<02:33,  2.51it/s] 62%|██████▏   | 615/1000 [04:09<02:33,  2.50it/s] 62%|██████▏   | 616/1000 [04:10<02:32,  2.51it/s] 62%|██████▏   | 617/1000 [04:10<02:36,  2.45it/s] 62%|██████▏   | 618/1000 [04:11<02:29,  2.56it/s] 62%|██████▏   | 619/1000 [04:11<02:29,  2.55it/s] 62%|██████▏   | 620/1000 [04:11<02:29,  2.54it/s]                                                   62%|██████▏   | 620/1000 [04:11<02:29,  2.54it/s] 62%|██████▏   | 621/1000 [04:12<02:34,  2.45it/s] 62%|██████▏   | 622/1000 [04:12<02:32,  2.48it/s] 62%|██████▏   | 623/1000 [04:13<02:35,  2.42it/s] 62%|██████▏   | 624/1000 [04:13<02:45,  2.27it/s] 62%|██████▎   | 625/1000 [04:14<02:44,  2.28it/s] 63%|██████▎   | 626/1000 [04:14<02:39,  2.35it/s] 63%|██████▎   | 627/1000 [04:14<02:31,  2.46it/s] 63%|██████▎   | 628/1000 [04:15<02:34,  2.41it/s] 63%|██████▎   | 629/1000 [04:15<02:31,  2.45it/s] 63%|██████▎   | 630/1000 [04:16<02:29,  2.48it/s]                                                   63%|██████▎   | 630/1000 [04:16<02:29,  2.48it/s] 63%|██████▎   | 631/1000 [04:16<02:24,  2.54it/s] 63%|██████▎   | 632/1000 [04:16<02:29,  2.46it/s] 63%|██████▎   | 633/1000 [04:17<02:28,  2.48it/s] 63%|██████▎   | 634/1000 [04:17<02:30,  2.42it/s] 64%|██████▎   | 635/1000 [04:18<02:33,  2.38it/s] 64%|██████▎   | 636/1000 [04:18<02:25,  2.50it/s] 64%|██████▎   | 637/1000 [04:19<02:30,  2.42it/s] 64%|██████▍   | 638/1000 [04:19<02:28,  2.44it/s] 64%|██████▍   | 639/1000 [04:19<02:37,  2.29it/s] 64%|██████▍   | 640/1000 [04:20<02:36,  2.29it/s]                                                   64%|██████▍   | 640/1000 [04:20<02:36,  2.29it/s] 64%|██████▍   | 641/1000 [04:20<02:36,  2.30it/s] 64%|██████▍   | 642/1000 [04:21<02:27,  2.42it/s] 64%|██████▍   | 643/1000 [04:21<02:25,  2.45it/s] 64%|██████▍   | 644/1000 [04:21<02:23,  2.48it/s] 64%|██████▍   | 645/1000 [04:22<02:21,  2.51it/s] 65%|██████▍   | 646/1000 [04:22<02:20,  2.53it/s] 65%|██████▍   | 647/1000 [04:23<02:18,  2.54it/s] 65%|██████▍   | 648/1000 [04:23<02:14,  2.62it/s] 65%|██████▍   | 649/1000 [04:23<02:19,  2.52it/s] 65%|██████▌   | 650/1000 [04:24<02:19,  2.51it/s]                                                   65%|██████▌   | 650/1000 [04:24<02:19,  2.51it/s]Saving model checkpoint to ./output/checkpoint-650
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 65%|██████▌   | 651/1000 [04:24<02:38,  2.20it/s] 65%|██████▌   | 652/1000 [04:25<02:32,  2.28it/s] 65%|██████▌   | 653/1000 [04:25<02:27,  2.35it/s] 65%|██████▌   | 654/1000 [04:26<02:28,  2.34it/s] 66%|██████▌   | 655/1000 [04:26<02:28,  2.33it/s] 66%|██████▌   | 656/1000 [04:26<02:24,  2.39it/s] 66%|██████▌   | 657/1000 [04:27<02:18,  2.48it/s] 66%|██████▌   | 658/1000 [04:27<02:16,  2.51it/s] 66%|██████▌   | 659/1000 [04:28<02:19,  2.45it/s] 66%|██████▌   | 660/1000 [04:28<02:17,  2.48it/s]                                                   66%|██████▌   | 660/1000 [04:28<02:17,  2.48it/s] 66%|██████▌   | 661/1000 [04:28<02:20,  2.41it/s] 66%|██████▌   | 662/1000 [04:29<02:18,  2.44it/s] 66%|██████▋   | 663/1000 [04:29<02:20,  2.40it/s] 66%|██████▋   | 664/1000 [04:30<02:18,  2.43it/s] 66%|██████▋   | 665/1000 [04:30<02:17,  2.44it/s] 67%|██████▋   | 666/1000 [04:30<02:15,  2.47it/s] 67%|██████▋   | 667/1000 [04:31<02:05,  2.66it/s] 67%|██████▋   | 668/1000 [04:31<02:10,  2.54it/s] 67%|██████▋   | 669/1000 [04:32<02:10,  2.54it/s] 67%|██████▋   | 670/1000 [04:32<02:10,  2.54it/s]                                                   67%|██████▋   | 670/1000 [04:32<02:10,  2.54it/s] 67%|██████▋   | 671/1000 [04:32<02:06,  2.60it/s] 67%|██████▋   | 672/1000 [04:33<02:07,  2.57it/s] 67%|██████▋   | 673/1000 [04:33<02:04,  2.62it/s] 67%|██████▋   | 674/1000 [04:34<02:04,  2.61it/s] 68%|██████▊   | 675/1000 [04:34<02:16,  2.38it/s] 68%|██████▊   | 676/1000 [04:34<02:13,  2.42it/s] 68%|██████▊   | 677/1000 [04:35<02:12,  2.45it/s] 68%|██████▊   | 678/1000 [04:35<02:14,  2.39it/s] 68%|██████▊   | 679/1000 [04:36<02:22,  2.25it/s] 68%|██████▊   | 680/1000 [04:36<02:21,  2.26it/s]                                                   68%|██████▊   | 680/1000 [04:36<02:21,  2.26it/s] 68%|██████▊   | 681/1000 [04:37<02:17,  2.32it/s] 68%|██████▊   | 682/1000 [04:37<02:13,  2.38it/s] 68%|██████▊   | 683/1000 [04:37<02:14,  2.36it/s] 68%|██████▊   | 684/1000 [04:38<02:11,  2.40it/s] 68%|██████▊   | 685/1000 [04:38<02:09,  2.43it/s] 69%|██████▊   | 686/1000 [04:39<02:07,  2.46it/s] 69%|██████▊   | 687/1000 [04:39<02:06,  2.48it/s] 69%|██████▉   | 688/1000 [04:39<02:01,  2.57it/s] 69%|██████▉   | 689/1000 [04:40<02:01,  2.55it/s] 69%|██████▉   | 690/1000 [04:40<02:02,  2.54it/s]                                                   69%|██████▉   | 690/1000 [04:40<02:02,  2.54it/s] 69%|██████▉   | 691/1000 [04:41<02:05,  2.47it/s] 69%|██████▉   | 692/1000 [04:41<02:04,  2.48it/s] 69%|██████▉   | 693/1000 [04:41<01:59,  2.56it/s] 69%|██████▉   | 694/1000 [04:42<01:59,  2.57it/s] 70%|██████▉   | 695/1000 [04:42<01:58,  2.57it/s] 70%|██████▉   | 696/1000 [04:43<02:02,  2.48it/s] 70%|██████▉   | 697/1000 [04:43<02:17,  2.20it/s] 70%|██████▉   | 698/1000 [04:44<02:11,  2.30it/s] 70%|██████▉   | 699/1000 [04:44<02:08,  2.35it/s] 70%|███████   | 700/1000 [04:44<02:01,  2.46it/s]                                                   70%|███████   | 700/1000 [04:44<02:01,  2.46it/s]Saving model checkpoint to ./output/checkpoint-700
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 70%|███████   | 701/1000 [04:45<01:58,  2.52it/s] 70%|███████   | 702/1000 [04:45<01:57,  2.53it/s] 70%|███████   | 703/1000 [04:45<01:56,  2.54it/s] 70%|███████   | 704/1000 [04:46<01:52,  2.63it/s] 70%|███████   | 705/1000 [04:46<01:50,  2.68it/s] 71%|███████   | 706/1000 [04:47<01:52,  2.62it/s] 71%|███████   | 707/1000 [04:47<01:52,  2.60it/s] 71%|███████   | 708/1000 [04:47<01:56,  2.50it/s] 71%|███████   | 709/1000 [04:48<01:55,  2.51it/s] 71%|███████   | 710/1000 [04:48<01:55,  2.52it/s]                                                   71%|███████   | 710/1000 [04:48<01:55,  2.52it/s] 71%|███████   | 711/1000 [04:49<01:58,  2.44it/s] 71%|███████   | 712/1000 [04:49<01:56,  2.47it/s] 71%|███████▏  | 713/1000 [04:49<01:59,  2.41it/s] 71%|███████▏  | 714/1000 [04:50<02:00,  2.37it/s] 72%|███████▏  | 715/1000 [04:50<01:58,  2.41it/s] 72%|███████▏  | 716/1000 [04:51<01:55,  2.46it/s] 72%|███████▏  | 717/1000 [04:51<01:51,  2.54it/s] 72%|███████▏  | 718/1000 [04:52<02:01,  2.33it/s] 72%|███████▏  | 719/1000 [04:52<02:01,  2.31it/s] 72%|███████▏  | 720/1000 [04:52<01:58,  2.37it/s]                                                   72%|███████▏  | 720/1000 [04:52<01:58,  2.37it/s] 72%|███████▏  | 721/1000 [04:53<01:56,  2.40it/s] 72%|███████▏  | 722/1000 [04:53<01:57,  2.37it/s] 72%|███████▏  | 723/1000 [04:54<01:54,  2.42it/s] 72%|███████▏  | 724/1000 [04:54<01:52,  2.46it/s] 72%|███████▎  | 725/1000 [04:54<01:47,  2.57it/s] 73%|███████▎  | 726/1000 [04:55<01:47,  2.55it/s] 73%|███████▎  | 727/1000 [04:55<01:46,  2.55it/s] 73%|███████▎  | 728/1000 [04:56<01:46,  2.55it/s] 73%|███████▎  | 729/1000 [04:56<01:46,  2.54it/s] 73%|███████▎  | 730/1000 [04:56<01:43,  2.62it/s]                                                   73%|███████▎  | 730/1000 [04:56<01:43,  2.62it/s] 73%|███████▎  | 731/1000 [04:57<01:43,  2.59it/s] 73%|███████▎  | 732/1000 [04:57<01:44,  2.57it/s] 73%|███████▎  | 733/1000 [04:57<01:43,  2.57it/s] 73%|███████▎  | 734/1000 [04:58<01:43,  2.56it/s] 74%|███████▎  | 735/1000 [04:58<01:43,  2.56it/s] 74%|███████▎  | 736/1000 [04:59<01:43,  2.55it/s] 74%|███████▎  | 737/1000 [04:59<01:40,  2.62it/s] 74%|███████▍  | 738/1000 [04:59<01:39,  2.64it/s] 74%|███████▍  | 739/1000 [05:00<01:43,  2.52it/s] 74%|███████▍  | 740/1000 [05:00<01:43,  2.51it/s]                                                   74%|███████▍  | 740/1000 [05:00<01:43,  2.51it/s] 74%|███████▍  | 741/1000 [05:01<01:39,  2.60it/s] 74%|███████▍  | 742/1000 [05:01<01:43,  2.50it/s] 74%|███████▍  | 743/1000 [05:01<01:42,  2.51it/s] 74%|███████▍  | 744/1000 [05:02<01:39,  2.58it/s] 74%|███████▍  | 745/1000 [05:02<01:49,  2.33it/s] 75%|███████▍  | 746/1000 [05:03<01:46,  2.38it/s] 75%|███████▍  | 747/1000 [05:03<01:43,  2.43it/s] 75%|███████▍  | 748/1000 [05:04<01:43,  2.45it/s] 75%|███████▍  | 749/1000 [05:04<01:38,  2.55it/s] 75%|███████▌  | 750/1000 [05:04<01:35,  2.63it/s]                                                   75%|███████▌  | 750/1000 [05:04<01:35,  2.63it/s]Saving model checkpoint to ./output/checkpoint-750
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 75%|███████▌  | 751/1000 [05:05<01:38,  2.52it/s] 75%|███████▌  | 752/1000 [05:05<01:37,  2.54it/s] 75%|███████▌  | 753/1000 [05:05<01:37,  2.53it/s] 75%|███████▌  | 754/1000 [05:06<01:37,  2.53it/s] 76%|███████▌  | 755/1000 [05:06<01:37,  2.52it/s] 76%|███████▌  | 756/1000 [05:07<01:37,  2.51it/s] 76%|███████▌  | 757/1000 [05:07<01:33,  2.59it/s] 76%|███████▌  | 758/1000 [05:07<01:34,  2.57it/s] 76%|███████▌  | 759/1000 [05:08<01:32,  2.62it/s] 76%|███████▌  | 760/1000 [05:08<01:32,  2.60it/s]                                                   76%|███████▌  | 760/1000 [05:08<01:32,  2.60it/s] 76%|███████▌  | 761/1000 [05:09<01:33,  2.56it/s] 76%|███████▌  | 762/1000 [05:09<01:31,  2.61it/s] 76%|███████▋  | 763/1000 [05:09<01:31,  2.58it/s] 76%|███████▋  | 764/1000 [05:10<01:31,  2.58it/s] 76%|███████▋  | 765/1000 [05:10<01:29,  2.64it/s] 77%|███████▋  | 766/1000 [05:10<01:27,  2.67it/s] 77%|███████▋  | 767/1000 [05:11<01:31,  2.54it/s] 77%|███████▋  | 768/1000 [05:11<01:31,  2.54it/s] 77%|███████▋  | 769/1000 [05:12<01:31,  2.53it/s] 77%|███████▋  | 770/1000 [05:12<01:41,  2.27it/s]                                                   77%|███████▋  | 770/1000 [05:12<01:41,  2.27it/s] 77%|███████▋  | 771/1000 [05:13<01:31,  2.49it/s] 77%|███████▋  | 772/1000 [05:13<01:28,  2.56it/s] 77%|███████▋  | 773/1000 [05:13<01:29,  2.55it/s] 77%|███████▋  | 774/1000 [05:14<01:28,  2.54it/s] 78%|███████▊  | 775/1000 [05:14<01:31,  2.47it/s] 78%|███████▊  | 776/1000 [05:15<01:30,  2.47it/s] 78%|███████▊  | 777/1000 [05:15<01:27,  2.55it/s] 78%|███████▊  | 778/1000 [05:15<01:27,  2.54it/s] 78%|███████▊  | 779/1000 [05:16<01:30,  2.45it/s] 78%|███████▊  | 780/1000 [05:16<01:29,  2.46it/s]                                                   78%|███████▊  | 780/1000 [05:16<01:29,  2.46it/s] 78%|███████▊  | 781/1000 [05:17<01:29,  2.46it/s] 78%|███████▊  | 782/1000 [05:17<01:28,  2.45it/s] 78%|███████▊  | 783/1000 [05:17<01:27,  2.47it/s] 78%|███████▊  | 784/1000 [05:18<01:30,  2.39it/s] 78%|███████▊  | 785/1000 [05:18<01:28,  2.42it/s] 79%|███████▊  | 786/1000 [05:19<01:30,  2.37it/s] 79%|███████▊  | 787/1000 [05:19<01:26,  2.46it/s] 79%|███████▉  | 788/1000 [05:19<01:28,  2.40it/s] 79%|███████▉  | 789/1000 [05:20<01:24,  2.50it/s] 79%|███████▉  | 790/1000 [05:20<01:21,  2.57it/s]                                                   79%|███████▉  | 790/1000 [05:20<01:21,  2.57it/s] 79%|███████▉  | 791/1000 [05:21<01:19,  2.64it/s] 79%|███████▉  | 792/1000 [05:21<01:19,  2.62it/s] 79%|███████▉  | 793/1000 [05:21<01:19,  2.59it/s] 79%|███████▉  | 794/1000 [05:22<01:24,  2.43it/s] 80%|███████▉  | 795/1000 [05:22<01:23,  2.45it/s] 80%|███████▉  | 796/1000 [05:23<01:24,  2.41it/s] 80%|███████▉  | 797/1000 [05:23<01:25,  2.38it/s] 80%|███████▉  | 798/1000 [05:23<01:25,  2.35it/s] 80%|███████▉  | 799/1000 [05:24<01:24,  2.38it/s] 80%|████████  | 800/1000 [05:24<01:25,  2.35it/s]                                                   80%|████████  | 800/1000 [05:24<01:25,  2.35it/s]Saving model checkpoint to ./output/checkpoint-800
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 80%|████████  | 801/1000 [05:25<01:31,  2.18it/s] 80%|████████  | 802/1000 [05:25<01:29,  2.22it/s] 80%|████████  | 803/1000 [05:26<01:25,  2.30it/s] 80%|████████  | 804/1000 [05:26<01:20,  2.42it/s] 80%|████████  | 805/1000 [05:26<01:17,  2.50it/s] 81%|████████  | 806/1000 [05:27<01:14,  2.59it/s] 81%|████████  | 807/1000 [05:27<01:14,  2.57it/s] 81%|████████  | 808/1000 [05:28<01:15,  2.56it/s] 81%|████████  | 809/1000 [05:28<01:16,  2.48it/s] 81%|████████  | 810/1000 [05:28<01:16,  2.50it/s]                                                   81%|████████  | 810/1000 [05:28<01:16,  2.50it/s] 81%|████████  | 811/1000 [05:29<01:17,  2.45it/s] 81%|████████  | 812/1000 [05:29<01:16,  2.47it/s] 81%|████████▏ | 813/1000 [05:30<01:15,  2.48it/s] 81%|████████▏ | 814/1000 [05:30<01:14,  2.51it/s] 82%|████████▏ | 815/1000 [05:30<01:15,  2.45it/s] 82%|████████▏ | 816/1000 [05:31<01:14,  2.47it/s] 82%|████████▏ | 817/1000 [05:31<01:21,  2.25it/s] 82%|████████▏ | 818/1000 [05:32<01:15,  2.40it/s] 82%|████████▏ | 819/1000 [05:32<01:14,  2.44it/s] 82%|████████▏ | 820/1000 [05:32<01:11,  2.52it/s]                                                   82%|████████▏ | 820/1000 [05:32<01:11,  2.52it/s] 82%|████████▏ | 821/1000 [05:33<01:06,  2.71it/s] 82%|████████▏ | 822/1000 [05:33<01:09,  2.56it/s] 82%|████████▏ | 823/1000 [05:34<01:09,  2.55it/s] 82%|████████▏ | 824/1000 [05:34<01:11,  2.48it/s] 82%|████████▎ | 825/1000 [05:34<01:09,  2.50it/s] 83%|████████▎ | 826/1000 [05:35<01:11,  2.45it/s] 83%|████████▎ | 827/1000 [05:35<01:09,  2.49it/s] 83%|████████▎ | 828/1000 [05:36<01:07,  2.55it/s] 83%|████████▎ | 829/1000 [05:36<01:05,  2.62it/s] 83%|████████▎ | 830/1000 [05:36<01:05,  2.58it/s]                                                   83%|████████▎ | 830/1000 [05:36<01:05,  2.58it/s] 83%|████████▎ | 831/1000 [05:37<01:05,  2.58it/s] 83%|████████▎ | 832/1000 [05:37<01:05,  2.58it/s] 83%|████████▎ | 833/1000 [05:38<01:03,  2.64it/s] 83%|████████▎ | 834/1000 [05:38<01:05,  2.54it/s] 84%|████████▎ | 835/1000 [05:38<01:03,  2.60it/s] 84%|████████▎ | 836/1000 [05:39<01:01,  2.66it/s] 84%|████████▎ | 837/1000 [05:39<01:02,  2.62it/s] 84%|████████▍ | 838/1000 [05:39<01:00,  2.67it/s] 84%|████████▍ | 839/1000 [05:40<00:59,  2.72it/s] 84%|████████▍ | 840/1000 [05:40<01:02,  2.58it/s]                                                  {'loss': 1.1672, 'grad_norm': 0.5750606656074524, 'learning_rate': 9.9e-06, 'epoch': 0.0}
{'loss': 1.2242, 'grad_norm': 1.4041211605072021, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.01}
{'loss': 1.4309, 'grad_norm': 0.8295020461082458, 'learning_rate': 9.7e-06, 'epoch': 0.01}
{'loss': 1.4078, 'grad_norm': 1.0180370807647705, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.01}
{'loss': 1.3965, 'grad_norm': 0.8932903409004211, 'learning_rate': 9.5e-06, 'epoch': 0.02}
{'loss': 1.4, 'grad_norm': 0.8970229029655457, 'learning_rate': 9.4e-06, 'epoch': 0.02}
{'loss': 1.473, 'grad_norm': 1.0811915397644043, 'learning_rate': 9.3e-06, 'epoch': 0.03}
{'loss': 1.4309, 'grad_norm': 1.5092614889144897, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.03}
{'loss': 1.1191, 'grad_norm': 1.3466817140579224, 'learning_rate': 9.100000000000001e-06, 'epoch': 0.03}
{'loss': 1.2805, 'grad_norm': 1.2847670316696167, 'learning_rate': 9e-06, 'epoch': 0.04}
{'loss': 1.5203, 'grad_norm': 1.124829649925232, 'learning_rate': 8.900000000000001e-06, 'epoch': 0.04}
{'loss': 1.3945, 'grad_norm': 2.04046630859375, 'learning_rate': 8.8e-06, 'epoch': 0.04}
{'loss': 1.298, 'grad_norm': 1.2887004613876343, 'learning_rate': 8.700000000000001e-06, 'epoch': 0.05}
{'loss': 1.1754, 'grad_norm': 1.1815941333770752, 'learning_rate': 8.6e-06, 'epoch': 0.05}
{'loss': 1.4742, 'grad_norm': 1.7070242166519165, 'learning_rate': 8.5e-06, 'epoch': 0.06}
{'loss': 1.3006, 'grad_norm': 1.1649190187454224, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.06}
{'loss': 1.4074, 'grad_norm': 1.8348442316055298, 'learning_rate': 8.3e-06, 'epoch': 0.06}
{'loss': 1.2184, 'grad_norm': 1.6197775602340698, 'learning_rate': 8.2e-06, 'epoch': 0.07}
{'loss': 1.4004, 'grad_norm': 1.4365527629852295, 'learning_rate': 8.1e-06, 'epoch': 0.07}
{'loss': 1.3854, 'grad_norm': 1.440063714981079, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.07}
{'loss': 1.3402, 'grad_norm': 1.4194040298461914, 'learning_rate': 7.9e-06, 'epoch': 0.08}
{'loss': 1.291, 'grad_norm': 1.3050247430801392, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.08}
{'loss': 1.1523, 'grad_norm': 2.2691779136657715, 'learning_rate': 7.7e-06, 'epoch': 0.09}
{'loss': 1.3719, 'grad_norm': 1.5343912839889526, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.09}
{'loss': 1.2264, 'grad_norm': 1.5394141674041748, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.09}
{'loss': 1.3695, 'grad_norm': 1.4285556077957153, 'learning_rate': 7.4e-06, 'epoch': 0.1}
{'loss': 1.384, 'grad_norm': 1.80894136428833, 'learning_rate': 7.3e-06, 'epoch': 0.1}
{'loss': 1.3613, 'grad_norm': 2.1463305950164795, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.1}
{'loss': 1.2527, 'grad_norm': 2.510646343231201, 'learning_rate': 7.100000000000001e-06, 'epoch': 0.11}
{'loss': 1.3539, 'grad_norm': 2.392282247543335, 'learning_rate': 7e-06, 'epoch': 0.11}
{'loss': 1.1092, 'grad_norm': 1.573515772819519, 'learning_rate': 6.9e-06, 'epoch': 0.12}
{'loss': 1.06, 'grad_norm': 1.4680829048156738, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.12}
{'loss': 1.4594, 'grad_norm': 1.4962959289550781, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.12}
{'loss': 1.2762, 'grad_norm': 1.7487889528274536, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.13}
{'loss': 1.3699, 'grad_norm': 2.6125168800354004, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.13}
{'loss': 1.2695, 'grad_norm': 1.4249179363250732, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.13}
{'loss': 1.393, 'grad_norm': 1.966158151626587, 'learning_rate': 6.300000000000001e-06, 'epoch': 0.14}
{'loss': 1.1686, 'grad_norm': 1.7168519496917725, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.14}
{'loss': 1.5469, 'grad_norm': 1.7952702045440674, 'learning_rate': 6.1e-06, 'epoch': 0.14}
{'loss': 1.1479, 'grad_norm': 1.576263189315796, 'learning_rate': 6e-06, 'epoch': 0.15}
{'loss': 1.3391, 'grad_norm': 1.4978539943695068, 'learning_rate': 5.9e-06, 'epoch': 0.15}
{'loss': 1.3543, 'grad_norm': 1.6384111642837524, 'learning_rate': 5.8e-06, 'epoch': 0.16}
{'loss': 1.2742, 'grad_norm': 1.5904899835586548, 'learning_rate': 5.7e-06, 'epoch': 0.16}
{'loss': 1.3805, 'grad_norm': 1.8489811420440674, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.16}
{'loss': 1.0398, 'grad_norm': 1.5756850242614746, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.17}
{'loss': 1.2197, 'grad_norm': 1.4772545099258423, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.17}
{'loss': 1.4578, 'grad_norm': 1.3743460178375244, 'learning_rate': 5.300000000000001e-06, 'epoch': 0.17}
{'loss': 1.1746, 'grad_norm': 1.579722285270691, 'learning_rate': 5.2e-06, 'epoch': 0.18}
{'loss': 1.1941, 'grad_norm': 1.6170941591262817, 'learning_rate': 5.1e-06, 'epoch': 0.18}
{'loss': 1.3242, 'grad_norm': 1.4691075086593628, 'learning_rate': 5e-06, 'epoch': 0.19}
{'loss': 1.5078, 'grad_norm': 1.5524446964263916, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.19}
{'loss': 1.5516, 'grad_norm': 1.6203957796096802, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.19}
{'loss': 1.3217, 'grad_norm': 1.4307951927185059, 'learning_rate': 4.7e-06, 'epoch': 0.2}
{'loss': 1.3879, 'grad_norm': 1.483506441116333, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.2}
{'loss': 1.1635, 'grad_norm': 1.7907016277313232, 'learning_rate': 4.5e-06, 'epoch': 0.2}
{'loss': 1.4609, 'grad_norm': 2.4740822315216064, 'learning_rate': 4.4e-06, 'epoch': 0.21}
{'loss': 1.4555, 'grad_norm': 1.5109120607376099, 'learning_rate': 4.3e-06, 'epoch': 0.21}
{'loss': 1.3172, 'grad_norm': 2.2133634090423584, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.22}
{'loss': 1.2336, 'grad_norm': 2.4027531147003174, 'learning_rate': 4.1e-06, 'epoch': 0.22}
{'loss': 1.0832, 'grad_norm': 1.6614677906036377, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.22}
{'loss': 1.3672, 'grad_norm': 1.6601665019989014, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.23}
{'loss': 1.3473, 'grad_norm': 1.9695998430252075, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.23}
{'loss': 1.3092, 'grad_norm': 2.1182701587677, 'learning_rate': 3.7e-06, 'epoch': 0.23}
{'loss': 1.3203, 'grad_norm': 1.777315616607666, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.24}
{'loss': 1.2227, 'grad_norm': 1.542165994644165, 'learning_rate': 3.5e-06, 'epoch': 0.24}
{'loss': 1.2746, 'grad_norm': 1.7191613912582397, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.25}
{'loss': 1.5227, 'grad_norm': 1.5825824737548828, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.25}
{'loss': 1.2205, 'grad_norm': 1.6447373628616333, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.25}
{'loss': 1.3813, 'grad_norm': 1.695857286453247, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.26}
{'loss': 1.4492, 'grad_norm': 2.28294038772583, 'learning_rate': 3e-06, 'epoch': 0.26}
{'loss': 1.2111, 'grad_norm': 2.3682897090911865, 'learning_rate': 2.9e-06, 'epoch': 0.26}
{'loss': 1.3965, 'grad_norm': 1.6493382453918457, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.27}
{'loss': 1.3906, 'grad_norm': 2.5332400798797607, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.27}
{'loss': 1.2242, 'grad_norm': 1.73280930519104, 'learning_rate': 2.6e-06, 'epoch': 0.28}
{'loss': 1.2641, 'grad_norm': 2.6915383338928223, 'learning_rate': 2.5e-06, 'epoch': 0.28}
{'loss': 1.2131, 'grad_norm': 1.7507878541946411, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.28}
{'loss': 1.3225, 'grad_norm': 1.5935834646224976, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.29}
{'loss': 1.2363, 'grad_norm': 2.0205698013305664, 'learning_rate': 2.2e-06, 'epoch': 0.29}
{'loss': 1.3639, 'grad_norm': 2.4854397773742676, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.29}
{'loss': 1.3355, 'grad_norm': 1.6910303831100464, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.3}
{'loss': 1.2465, 'grad_norm': 1.8511475324630737, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.3}
{'loss': 1.2205, 'grad_norm': 2.1553609371185303, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.3}
{'loss': 1.2164, 'grad_norm': 2.1741912364959717, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.31}
 84%|████████▍ | 840/1000 [05:40<01:02,  2.58it/s] 84%|████████▍ | 841/1000 [05:41<01:01,  2.57it/s] 84%|████████▍ | 842/1000 [05:41<01:06,  2.36it/s] 84%|████████▍ | 843/1000 [05:42<01:07,  2.34it/s] 84%|████████▍ | 844/1000 [05:42<01:07,  2.32it/s] 84%|████████▍ | 845/1000 [05:42<01:03,  2.44it/s] 85%|████████▍ | 846/1000 [05:43<01:03,  2.41it/s] 85%|████████▍ | 847/1000 [05:43<01:02,  2.44it/s] 85%|████████▍ | 848/1000 [05:44<01:00,  2.52it/s] 85%|████████▍ | 849/1000 [05:44<01:00,  2.51it/s] 85%|████████▌ | 850/1000 [05:44<00:57,  2.59it/s]                                                   85%|████████▌ | 850/1000 [05:44<00:57,  2.59it/s]Saving model checkpoint to ./output/checkpoint-850
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 85%|████████▌ | 851/1000 [05:45<01:01,  2.44it/s] 85%|████████▌ | 852/1000 [05:45<01:01,  2.40it/s] 85%|████████▌ | 853/1000 [05:46<01:00,  2.44it/s] 85%|████████▌ | 854/1000 [05:46<00:59,  2.46it/s] 86%|████████▌ | 855/1000 [05:46<00:56,  2.55it/s] 86%|████████▌ | 856/1000 [05:47<00:54,  2.63it/s] 86%|████████▌ | 857/1000 [05:47<00:57,  2.51it/s] 86%|████████▌ | 858/1000 [05:48<00:56,  2.51it/s] 86%|████████▌ | 859/1000 [05:48<00:55,  2.52it/s] 86%|████████▌ | 860/1000 [05:48<00:55,  2.52it/s]                                                   86%|████████▌ | 860/1000 [05:48<00:55,  2.52it/s] 86%|████████▌ | 861/1000 [05:49<00:55,  2.51it/s] 86%|████████▌ | 862/1000 [05:49<00:55,  2.51it/s] 86%|████████▋ | 863/1000 [05:50<00:54,  2.49it/s] 86%|████████▋ | 864/1000 [05:50<00:53,  2.56it/s] 86%|████████▋ | 865/1000 [05:50<00:53,  2.54it/s] 87%|████████▋ | 866/1000 [05:51<00:51,  2.59it/s] 87%|████████▋ | 867/1000 [05:51<00:51,  2.58it/s] 87%|████████▋ | 868/1000 [05:52<00:56,  2.32it/s] 87%|████████▋ | 869/1000 [05:52<00:55,  2.38it/s] 87%|████████▋ | 870/1000 [05:52<00:53,  2.42it/s]                                                   87%|████████▋ | 870/1000 [05:52<00:53,  2.42it/s] 87%|████████▋ | 871/1000 [05:53<00:52,  2.46it/s] 87%|████████▋ | 872/1000 [05:53<00:51,  2.48it/s] 87%|████████▋ | 873/1000 [05:54<00:49,  2.55it/s] 87%|████████▋ | 874/1000 [05:54<00:49,  2.54it/s] 88%|████████▊ | 875/1000 [05:54<00:48,  2.59it/s] 88%|████████▊ | 876/1000 [05:55<00:47,  2.63it/s] 88%|████████▊ | 877/1000 [05:55<00:47,  2.60it/s] 88%|████████▊ | 878/1000 [05:55<00:45,  2.66it/s] 88%|████████▊ | 879/1000 [05:56<00:46,  2.62it/s] 88%|████████▊ | 880/1000 [05:56<00:47,  2.52it/s]                                                   88%|████████▊ | 880/1000 [05:56<00:47,  2.52it/s] 88%|████████▊ | 881/1000 [05:57<00:47,  2.52it/s] 88%|████████▊ | 882/1000 [05:57<00:46,  2.52it/s] 88%|████████▊ | 883/1000 [05:57<00:47,  2.44it/s] 88%|████████▊ | 884/1000 [05:58<00:48,  2.40it/s] 88%|████████▊ | 885/1000 [05:58<00:47,  2.42it/s] 89%|████████▊ | 886/1000 [05:59<00:46,  2.45it/s] 89%|████████▊ | 887/1000 [05:59<00:45,  2.47it/s] 89%|████████▉ | 888/1000 [05:59<00:45,  2.49it/s] 89%|████████▉ | 889/1000 [06:00<00:44,  2.48it/s] 89%|████████▉ | 890/1000 [06:00<00:45,  2.42it/s]                                                   89%|████████▉ | 890/1000 [06:00<00:45,  2.42it/s] 89%|████████▉ | 891/1000 [06:01<00:44,  2.44it/s] 89%|████████▉ | 892/1000 [06:01<00:47,  2.26it/s] 89%|████████▉ | 893/1000 [06:02<00:44,  2.39it/s] 89%|████████▉ | 894/1000 [06:02<00:42,  2.48it/s] 90%|████████▉ | 895/1000 [06:02<00:42,  2.49it/s] 90%|████████▉ | 896/1000 [06:03<00:41,  2.51it/s] 90%|████████▉ | 897/1000 [06:03<00:41,  2.50it/s] 90%|████████▉ | 898/1000 [06:04<00:41,  2.43it/s] 90%|████████▉ | 899/1000 [06:04<00:41,  2.46it/s] 90%|█████████ | 900/1000 [06:04<00:40,  2.49it/s]                                                   90%|█████████ | 900/1000 [06:04<00:40,  2.49it/s]Saving model checkpoint to ./output/checkpoint-900
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 90%|█████████ | 901/1000 [06:05<00:39,  2.51it/s] 90%|█████████ | 902/1000 [06:05<00:40,  2.43it/s] 90%|█████████ | 903/1000 [06:06<00:38,  2.51it/s] 90%|█████████ | 904/1000 [06:06<00:39,  2.44it/s] 90%|█████████ | 905/1000 [06:06<00:37,  2.52it/s] 91%|█████████ | 906/1000 [06:07<00:38,  2.45it/s] 91%|█████████ | 907/1000 [06:07<00:38,  2.40it/s] 91%|█████████ | 908/1000 [06:08<00:37,  2.43it/s] 91%|█████████ | 909/1000 [06:08<00:37,  2.45it/s] 91%|█████████ | 910/1000 [06:09<00:37,  2.39it/s]                                                   91%|█████████ | 910/1000 [06:09<00:37,  2.39it/s] 91%|█████████ | 911/1000 [06:09<00:36,  2.42it/s] 91%|█████████ | 912/1000 [06:09<00:36,  2.44it/s] 91%|█████████▏| 913/1000 [06:10<00:31,  2.73it/s] 91%|█████████▏| 914/1000 [06:10<00:35,  2.45it/s] 92%|█████████▏| 915/1000 [06:10<00:34,  2.48it/s] 92%|█████████▏| 916/1000 [06:11<00:32,  2.58it/s] 92%|█████████▏| 917/1000 [06:11<00:32,  2.57it/s] 92%|█████████▏| 918/1000 [06:12<00:32,  2.54it/s] 92%|█████████▏| 919/1000 [06:12<00:32,  2.47it/s] 92%|█████████▏| 920/1000 [06:12<00:32,  2.48it/s]                                                   92%|█████████▏| 920/1000 [06:12<00:32,  2.48it/s] 92%|█████████▏| 921/1000 [06:13<00:31,  2.48it/s] 92%|█████████▏| 922/1000 [06:13<00:30,  2.57it/s] 92%|█████████▏| 923/1000 [06:14<00:30,  2.55it/s] 92%|█████████▏| 924/1000 [06:14<00:29,  2.54it/s] 92%|█████████▎| 925/1000 [06:14<00:29,  2.54it/s] 93%|█████████▎| 926/1000 [06:15<00:29,  2.52it/s] 93%|█████████▎| 927/1000 [06:15<00:29,  2.51it/s] 93%|█████████▎| 928/1000 [06:16<00:29,  2.44it/s] 93%|█████████▎| 929/1000 [06:16<00:28,  2.48it/s] 93%|█████████▎| 930/1000 [06:16<00:27,  2.58it/s]                                                   93%|█████████▎| 930/1000 [06:16<00:27,  2.58it/s] 93%|█████████▎| 931/1000 [06:17<00:26,  2.56it/s] 93%|█████████▎| 932/1000 [06:17<00:27,  2.47it/s] 93%|█████████▎| 933/1000 [06:18<00:26,  2.49it/s] 93%|█████████▎| 934/1000 [06:18<00:26,  2.48it/s] 94%|█████████▎| 935/1000 [06:18<00:25,  2.57it/s] 94%|█████████▎| 936/1000 [06:19<00:24,  2.56it/s] 94%|█████████▎| 937/1000 [06:19<00:24,  2.55it/s] 94%|█████████▍| 938/1000 [06:20<00:24,  2.54it/s] 94%|█████████▍| 939/1000 [06:20<00:24,  2.53it/s] 94%|█████████▍| 940/1000 [06:20<00:25,  2.34it/s]                                                   94%|█████████▍| 940/1000 [06:20<00:25,  2.34it/s] 94%|█████████▍| 941/1000 [06:21<00:24,  2.45it/s] 94%|█████████▍| 942/1000 [06:21<00:23,  2.46it/s] 94%|█████████▍| 943/1000 [06:22<00:23,  2.47it/s] 94%|█████████▍| 944/1000 [06:22<00:22,  2.55it/s] 94%|█████████▍| 945/1000 [06:22<00:22,  2.47it/s] 95%|█████████▍| 946/1000 [06:23<00:21,  2.50it/s] 95%|█████████▍| 947/1000 [06:23<00:21,  2.50it/s] 95%|█████████▍| 948/1000 [06:24<00:20,  2.50it/s] 95%|█████████▍| 949/1000 [06:24<00:19,  2.57it/s] 95%|█████████▌| 950/1000 [06:24<00:19,  2.56it/s]                                                   95%|█████████▌| 950/1000 [06:24<00:19,  2.56it/s]Saving model checkpoint to ./output/checkpoint-950
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 95%|█████████▌| 951/1000 [06:25<00:20,  2.41it/s] 95%|█████████▌| 952/1000 [06:25<00:19,  2.45it/s] 95%|█████████▌| 953/1000 [06:26<00:18,  2.50it/s] 95%|█████████▌| 954/1000 [06:26<00:17,  2.58it/s] 96%|█████████▌| 955/1000 [06:26<00:17,  2.55it/s] 96%|█████████▌| 956/1000 [06:27<00:17,  2.55it/s] 96%|█████████▌| 957/1000 [06:27<00:16,  2.56it/s] 96%|█████████▌| 958/1000 [06:28<00:16,  2.55it/s] 96%|█████████▌| 959/1000 [06:28<00:16,  2.45it/s] 96%|█████████▌| 960/1000 [06:28<00:16,  2.40it/s]                                                   96%|█████████▌| 960/1000 [06:28<00:16,  2.40it/s] 96%|█████████▌| 961/1000 [06:29<00:15,  2.51it/s] 96%|█████████▌| 962/1000 [06:29<00:15,  2.44it/s] 96%|█████████▋| 963/1000 [06:30<00:15,  2.45it/s] 96%|█████████▋| 964/1000 [06:30<00:14,  2.41it/s] 96%|█████████▋| 965/1000 [06:31<00:15,  2.20it/s] 97%|█████████▋| 966/1000 [06:31<00:15,  2.23it/s] 97%|█████████▋| 967/1000 [06:31<00:14,  2.25it/s] 97%|█████████▋| 968/1000 [06:32<00:13,  2.39it/s] 97%|█████████▋| 969/1000 [06:32<00:12,  2.42it/s] 97%|█████████▋| 970/1000 [06:33<00:12,  2.44it/s]                                                   97%|█████████▋| 970/1000 [06:33<00:12,  2.44it/s] 97%|█████████▋| 971/1000 [06:33<00:11,  2.45it/s] 97%|█████████▋| 972/1000 [06:33<00:11,  2.48it/s] 97%|█████████▋| 973/1000 [06:34<00:11,  2.41it/s] 97%|█████████▋| 974/1000 [06:34<00:10,  2.43it/s] 98%|█████████▊| 975/1000 [06:35<00:09,  2.53it/s] 98%|█████████▊| 976/1000 [06:35<00:09,  2.46it/s] 98%|█████████▊| 977/1000 [06:35<00:09,  2.49it/s] 98%|█████████▊| 978/1000 [06:36<00:08,  2.51it/s] 98%|█████████▊| 979/1000 [06:36<00:08,  2.45it/s] 98%|█████████▊| 980/1000 [06:37<00:08,  2.46it/s]                                                   98%|█████████▊| 980/1000 [06:37<00:08,  2.46it/s] 98%|█████████▊| 981/1000 [06:37<00:07,  2.42it/s] 98%|█████████▊| 982/1000 [06:38<00:07,  2.39it/s] 98%|█████████▊| 983/1000 [06:38<00:07,  2.43it/s] 98%|█████████▊| 984/1000 [06:38<00:06,  2.54it/s] 98%|█████████▊| 985/1000 [06:39<00:05,  2.61it/s] 99%|█████████▊| 986/1000 [06:39<00:05,  2.65it/s] 99%|█████████▊| 987/1000 [06:39<00:04,  2.71it/s] 99%|█████████▉| 988/1000 [06:40<00:04,  2.57it/s] 99%|█████████▉| 989/1000 [06:40<00:04,  2.34it/s] 99%|█████████▉| 990/1000 [06:41<00:04,  2.39it/s]                                                   99%|█████████▉| 990/1000 [06:41<00:04,  2.39it/s] 99%|█████████▉| 991/1000 [06:41<00:03,  2.49it/s] 99%|█████████▉| 992/1000 [06:41<00:03,  2.50it/s] 99%|█████████▉| 993/1000 [06:42<00:02,  2.43it/s] 99%|█████████▉| 994/1000 [06:42<00:02,  2.44it/s]100%|█████████▉| 995/1000 [06:43<00:02,  2.47it/s]100%|█████████▉| 996/1000 [06:43<00:01,  2.51it/s]100%|█████████▉| 997/1000 [06:43<00:01,  2.51it/s]100%|█████████▉| 998/1000 [06:44<00:00,  2.59it/s]100%|█████████▉| 999/1000 [06:44<00:00,  2.51it/s]100%|██████████| 1000/1000 [06:45<00:00,  2.51it/s]                                                   100%|██████████| 1000/1000 [06:45<00:00,  2.51it/s]Saving model checkpoint to ./output/checkpoint-1000
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}



Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 1000/1000 [06:45<00:00,  2.51it/s]100%|██████████| 1000/1000 [06:45<00:00,  2.47it/s]

***** Running Prediction *****
  Num examples = 1
  Batch size = 4
{'loss': 1.2549, 'grad_norm': 1.582887053489685, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.31}
{'loss': 1.1371, 'grad_norm': 2.8286678791046143, 'learning_rate': 1.5e-06, 'epoch': 0.32}
{'loss': 1.352, 'grad_norm': 1.647103190422058, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.32}
{'loss': 1.4049, 'grad_norm': 1.6424273252487183, 'learning_rate': 1.3e-06, 'epoch': 0.32}
{'loss': 1.3256, 'grad_norm': 1.6624667644500732, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.33}
{'loss': 1.2041, 'grad_norm': 1.586791753768921, 'learning_rate': 1.1e-06, 'epoch': 0.33}
{'loss': 1.1078, 'grad_norm': 1.8336498737335205, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.33}
{'loss': 1.2773, 'grad_norm': 1.6861563920974731, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.34}
{'loss': 1.357, 'grad_norm': 1.8026243448257446, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.34}
{'loss': 1.2293, 'grad_norm': 2.7825679779052734, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.35}
{'loss': 1.0486, 'grad_norm': 1.5542677640914917, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.35}
{'loss': 1.142, 'grad_norm': 3.1035051345825195, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.35}
{'loss': 1.3432, 'grad_norm': 1.5427534580230713, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.36}
{'loss': 1.4352, 'grad_norm': 1.5615593194961548, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.36}
{'loss': 1.2523, 'grad_norm': 2.037004232406616, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.36}
{'loss': 1.1953, 'grad_norm': 1.84739089012146, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.37}
{'loss': 1.3707, 'grad_norm': 1.6771049499511719, 'learning_rate': 0.0, 'epoch': 0.37}
{'train_runtime': 405.3212, 'train_samples_per_second': 2.467, 'train_steps_per_second': 2.467, 'train_loss': 1.3054296875, 'epoch': 0.37}
  0%|          | 0/1 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 0.669 seconds.
Prefix dict has been built successfully.
100%|██████████| 1/1 [00:03<00:00,  3.18s/it]
