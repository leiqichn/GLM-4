Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]Loading checkpoint shards:  10%|â–ˆ         | 1/10 [00:00<00:00,  9.89it/s]Loading checkpoint shards:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:00<00:00, 12.24it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:00<00:00, 12.72it/s]Loading checkpoint shards:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:00<00:00, 13.04it/s]Loading checkpoint shards:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:00<00:00, 12.16it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 12.34it/s]
trainable params: 2,785,280 || all params: 9,402,736,640 || trainable%: 0.0296
Map:   0%|          | 0/2690 [00:00<?, ? examples/s]Map:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1000/2690 [00:02<00:04, 378.32 examples/s]Map:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2000/2690 [00:04<00:01, 408.10 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2690/2690 [00:06<00:00, 408.40 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2690/2690 [00:06<00:00, 404.41 examples/s]
train_dataset: Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 2690
})
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 103.90 examples/s]
val_dataset: Dataset({
    features: ['input_ids', 'output_ids'],
    num_rows: 1
})
Map:   0%|          | 0/1 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 116.00 examples/s]
max_steps is given, it will override any value given in num_train_epochs
test_dataset: Dataset({
    features: ['input_ids', 'output_ids'],
    num_rows: 1
})
[2024-08-04 15:14:04,937] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
***** Running training *****
  Num examples = 2,690
  Num Epochs = 1
  Instantaneous batch size per device = 1
  Total train batch size (w. parallel, distributed & accumulation) = 1
  Gradient Accumulation steps = 1
  Total optimization steps = 1,000
  Number of trainable parameters = 2,785,280
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4
[93m [WARNING] [0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible
  0%|          | 0/1000 [00:00<?, ?it/s]/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
  0%|          | 1/1000 [00:01<31:12,  1.87s/it]  0%|          | 2/1000 [00:02<16:43,  1.01s/it]  0%|          | 3/1000 [00:02<11:51,  1.40it/s]  0%|          | 4/1000 [00:03<09:47,  1.69it/s]  0%|          | 5/1000 [00:03<08:38,  1.92it/s]  1%|          | 6/1000 [00:03<07:57,  2.08it/s]  1%|          | 7/1000 [00:04<07:31,  2.20it/s]  1%|          | 8/1000 [00:04<07:11,  2.30it/s]  1%|          | 9/1000 [00:05<08:10,  2.02it/s]  1%|          | 10/1000 [00:05<07:37,  2.16it/s]                                                   1%|          | 10/1000 [00:05<07:37,  2.16it/s]  1%|          | 11/1000 [00:06<07:16,  2.27it/s]  1%|          | 12/1000 [00:06<06:54,  2.38it/s]  1%|â–         | 13/1000 [00:06<06:47,  2.42it/s]  1%|â–         | 14/1000 [00:07<06:32,  2.51it/s]  2%|â–         | 15/1000 [00:07<06:23,  2.57it/s]  2%|â–         | 16/1000 [00:07<06:15,  2.62it/s]  2%|â–         | 17/1000 [00:08<06:18,  2.60it/s]  2%|â–         | 18/1000 [00:08<06:11,  2.64it/s]  2%|â–         | 19/1000 [00:09<06:26,  2.54it/s]  2%|â–         | 20/1000 [00:09<06:13,  2.63it/s]                                                   2%|â–         | 20/1000 [00:09<06:13,  2.63it/s]  2%|â–         | 21/1000 [00:09<06:16,  2.60it/s]  2%|â–         | 22/1000 [00:10<06:16,  2.60it/s]  2%|â–         | 23/1000 [00:10<06:10,  2.64it/s]  2%|â–         | 24/1000 [00:11<06:26,  2.52it/s]  2%|â–Ž         | 25/1000 [00:11<06:24,  2.54it/s]  3%|â–Ž         | 26/1000 [00:11<06:23,  2.54it/s]  3%|â–Ž         | 27/1000 [00:12<06:35,  2.46it/s]  3%|â–Ž         | 28/1000 [00:12<06:42,  2.42it/s]  3%|â–Ž         | 29/1000 [00:13<06:33,  2.47it/s]  3%|â–Ž         | 30/1000 [00:13<06:40,  2.42it/s]                                                   3%|â–Ž         | 30/1000 [00:13<06:40,  2.42it/s]  3%|â–Ž         | 31/1000 [00:13<06:45,  2.39it/s]  3%|â–Ž         | 32/1000 [00:14<06:50,  2.36it/s]  3%|â–Ž         | 33/1000 [00:14<06:42,  2.40it/s]  3%|â–Ž         | 34/1000 [00:15<07:00,  2.30it/s]  4%|â–Ž         | 35/1000 [00:15<06:50,  2.35it/s]  4%|â–Ž         | 36/1000 [00:16<06:40,  2.41it/s]  4%|â–Ž         | 37/1000 [00:16<06:21,  2.52it/s]  4%|â–         | 38/1000 [00:16<06:22,  2.51it/s]  4%|â–         | 39/1000 [00:17<06:10,  2.59it/s]  4%|â–         | 40/1000 [00:17<06:23,  2.50it/s]                                                   4%|â–         | 40/1000 [00:17<06:23,  2.50it/s]  4%|â–         | 41/1000 [00:17<06:13,  2.57it/s]  4%|â–         | 42/1000 [00:18<06:16,  2.54it/s]  4%|â–         | 43/1000 [00:18<06:16,  2.54it/s]  4%|â–         | 44/1000 [00:19<06:27,  2.47it/s]  4%|â–         | 45/1000 [00:19<06:26,  2.47it/s]  5%|â–         | 46/1000 [00:19<06:23,  2.49it/s]  5%|â–         | 47/1000 [00:20<06:08,  2.58it/s]  5%|â–         | 48/1000 [00:20<05:59,  2.65it/s]  5%|â–         | 49/1000 [00:21<06:04,  2.61it/s]  5%|â–Œ         | 50/1000 [00:21<06:06,  2.59it/s]                                                   5%|â–Œ         | 50/1000 [00:21<06:06,  2.59it/s]Saving model checkpoint to ./output/checkpoint-50
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
  5%|â–Œ         | 51/1000 [00:21<06:28,  2.44it/s]  5%|â–Œ         | 52/1000 [00:22<06:25,  2.46it/s]  5%|â–Œ         | 53/1000 [00:22<06:13,  2.53it/s]  5%|â–Œ         | 54/1000 [00:23<06:15,  2.52it/s]  6%|â–Œ         | 55/1000 [00:23<06:16,  2.51it/s]  6%|â–Œ         | 56/1000 [00:23<06:09,  2.56it/s]  6%|â–Œ         | 57/1000 [00:24<07:01,  2.24it/s]  6%|â–Œ         | 58/1000 [00:24<07:01,  2.24it/s]  6%|â–Œ         | 59/1000 [00:25<06:59,  2.24it/s]  6%|â–Œ         | 60/1000 [00:25<06:48,  2.30it/s]                                                   6%|â–Œ         | 60/1000 [00:25<06:48,  2.30it/s]  6%|â–Œ         | 61/1000 [00:26<06:50,  2.29it/s]  6%|â–Œ         | 62/1000 [00:26<06:38,  2.35it/s]  6%|â–‹         | 63/1000 [00:27<06:42,  2.33it/s]  6%|â–‹         | 64/1000 [00:27<06:37,  2.36it/s]  6%|â–‹         | 65/1000 [00:27<06:21,  2.45it/s]  7%|â–‹         | 66/1000 [00:28<06:16,  2.48it/s]  7%|â–‹         | 67/1000 [00:28<06:15,  2.48it/s]  7%|â–‹         | 68/1000 [00:29<06:17,  2.47it/s]  7%|â–‹         | 69/1000 [00:29<06:25,  2.42it/s]  7%|â–‹         | 70/1000 [00:29<06:19,  2.45it/s]                                                   7%|â–‹         | 70/1000 [00:29<06:19,  2.45it/s]  7%|â–‹         | 71/1000 [00:30<06:25,  2.41it/s]  7%|â–‹         | 72/1000 [00:30<06:20,  2.44it/s]  7%|â–‹         | 73/1000 [00:31<06:24,  2.41it/s]  7%|â–‹         | 74/1000 [00:31<06:12,  2.49it/s]  8%|â–Š         | 75/1000 [00:31<06:09,  2.50it/s]  8%|â–Š         | 76/1000 [00:32<06:08,  2.51it/s]  8%|â–Š         | 77/1000 [00:32<06:09,  2.50it/s]  8%|â–Š         | 78/1000 [00:33<06:08,  2.50it/s]  8%|â–Š         | 79/1000 [00:33<06:18,  2.43it/s]  8%|â–Š         | 80/1000 [00:34<06:58,  2.20it/s]                                                   8%|â–Š         | 80/1000 [00:34<06:58,  2.20it/s]  8%|â–Š         | 81/1000 [00:34<06:43,  2.28it/s]  8%|â–Š         | 82/1000 [00:34<06:30,  2.35it/s]  8%|â–Š         | 83/1000 [00:35<06:23,  2.39it/s]  8%|â–Š         | 84/1000 [00:35<06:27,  2.37it/s]  8%|â–Š         | 85/1000 [00:36<06:18,  2.42it/s]  9%|â–Š         | 86/1000 [00:36<06:13,  2.44it/s]  9%|â–Š         | 87/1000 [00:36<05:58,  2.55it/s]  9%|â–‰         | 88/1000 [00:37<05:49,  2.61it/s]  9%|â–‰         | 89/1000 [00:37<06:05,  2.49it/s]  9%|â–‰         | 90/1000 [00:38<06:03,  2.51it/s]                                                   9%|â–‰         | 90/1000 [00:38<06:03,  2.51it/s]  9%|â–‰         | 91/1000 [00:38<05:52,  2.58it/s]  9%|â–‰         | 92/1000 [00:38<05:31,  2.74it/s]  9%|â–‰         | 93/1000 [00:39<05:49,  2.60it/s]  9%|â–‰         | 94/1000 [00:39<05:48,  2.60it/s] 10%|â–‰         | 95/1000 [00:39<05:39,  2.66it/s] 10%|â–‰         | 96/1000 [00:40<05:36,  2.68it/s] 10%|â–‰         | 97/1000 [00:40<05:53,  2.55it/s] 10%|â–‰         | 98/1000 [00:41<06:05,  2.47it/s] 10%|â–‰         | 99/1000 [00:41<05:54,  2.55it/s] 10%|â–ˆ         | 100/1000 [00:41<05:45,  2.60it/s]                                                   10%|â–ˆ         | 100/1000 [00:41<05:45,  2.60it/s]Saving model checkpoint to ./output/checkpoint-100
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 10%|â–ˆ         | 101/1000 [00:42<06:05,  2.46it/s] 10%|â–ˆ         | 102/1000 [00:42<06:02,  2.48it/s] 10%|â–ˆ         | 103/1000 [00:43<05:58,  2.50it/s] 10%|â–ˆ         | 104/1000 [00:43<05:57,  2.50it/s] 10%|â–ˆ         | 105/1000 [00:44<06:40,  2.24it/s] 11%|â–ˆ         | 106/1000 [00:44<06:17,  2.37it/s] 11%|â–ˆ         | 107/1000 [00:44<05:57,  2.50it/s] 11%|â–ˆ         | 108/1000 [00:45<05:57,  2.49it/s] 11%|â–ˆ         | 109/1000 [00:45<05:57,  2.49it/s] 11%|â–ˆ         | 110/1000 [00:45<05:55,  2.50it/s]                                                   11%|â–ˆ         | 110/1000 [00:45<05:55,  2.50it/s] 11%|â–ˆ         | 111/1000 [00:46<06:04,  2.44it/s] 11%|â–ˆ         | 112/1000 [00:46<05:51,  2.53it/s] 11%|â–ˆâ–        | 113/1000 [00:47<05:52,  2.52it/s] 11%|â–ˆâ–        | 114/1000 [00:47<05:51,  2.52it/s] 12%|â–ˆâ–        | 115/1000 [00:47<05:41,  2.59it/s] 12%|â–ˆâ–        | 116/1000 [00:48<05:42,  2.58it/s] 12%|â–ˆâ–        | 117/1000 [00:48<05:18,  2.77it/s] 12%|â–ˆâ–        | 118/1000 [00:48<05:16,  2.79it/s] 12%|â–ˆâ–        | 119/1000 [00:49<05:37,  2.61it/s] 12%|â–ˆâ–        | 120/1000 [00:49<05:29,  2.67it/s]                                                   12%|â–ˆâ–        | 120/1000 [00:49<05:29,  2.67it/s] 12%|â–ˆâ–        | 121/1000 [00:50<05:28,  2.68it/s] 12%|â–ˆâ–        | 122/1000 [00:50<05:32,  2.64it/s] 12%|â–ˆâ–        | 123/1000 [00:50<05:37,  2.60it/s] 12%|â–ˆâ–        | 124/1000 [00:51<05:40,  2.58it/s] 12%|â–ˆâ–Ž        | 125/1000 [00:51<05:42,  2.55it/s] 13%|â–ˆâ–Ž        | 126/1000 [00:52<05:43,  2.54it/s] 13%|â–ˆâ–Ž        | 127/1000 [00:52<05:55,  2.45it/s] 13%|â–ˆâ–Ž        | 128/1000 [00:52<06:03,  2.40it/s] 13%|â–ˆâ–Ž        | 129/1000 [00:53<06:30,  2.23it/s] 13%|â–ˆâ–Ž        | 130/1000 [00:53<06:17,  2.31it/s]                                                   13%|â–ˆâ–Ž        | 130/1000 [00:53<06:17,  2.31it/s] 13%|â–ˆâ–Ž        | 131/1000 [00:54<06:07,  2.37it/s] 13%|â–ˆâ–Ž        | 132/1000 [00:54<05:58,  2.42it/s] 13%|â–ˆâ–Ž        | 133/1000 [00:55<05:43,  2.53it/s] 13%|â–ˆâ–Ž        | 134/1000 [00:55<05:42,  2.53it/s] 14%|â–ˆâ–Ž        | 135/1000 [00:55<05:52,  2.46it/s] 14%|â–ˆâ–Ž        | 136/1000 [00:56<05:39,  2.54it/s] 14%|â–ˆâ–Ž        | 137/1000 [00:56<05:39,  2.54it/s] 14%|â–ˆâ–        | 138/1000 [00:56<05:31,  2.60it/s] 14%|â–ˆâ–        | 139/1000 [00:57<05:32,  2.59it/s] 14%|â–ˆâ–        | 140/1000 [00:57<05:34,  2.57it/s]                                                   14%|â–ˆâ–        | 140/1000 [00:57<05:34,  2.57it/s] 14%|â–ˆâ–        | 141/1000 [00:58<05:14,  2.73it/s] 14%|â–ˆâ–        | 142/1000 [00:58<05:32,  2.58it/s] 14%|â–ˆâ–        | 143/1000 [00:58<05:32,  2.57it/s] 14%|â–ˆâ–        | 144/1000 [00:59<05:35,  2.55it/s] 14%|â–ˆâ–        | 145/1000 [00:59<05:27,  2.61it/s] 15%|â–ˆâ–        | 146/1000 [01:00<05:30,  2.58it/s] 15%|â–ˆâ–        | 147/1000 [01:00<05:42,  2.49it/s] 15%|â–ˆâ–        | 148/1000 [01:00<05:50,  2.43it/s] 15%|â–ˆâ–        | 149/1000 [01:01<05:46,  2.46it/s] 15%|â–ˆâ–Œ        | 150/1000 [01:01<05:32,  2.56it/s]                                                   15%|â–ˆâ–Œ        | 150/1000 [01:01<05:32,  2.56it/s]Saving model checkpoint to ./output/checkpoint-150
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 15%|â–ˆâ–Œ        | 151/1000 [01:02<06:00,  2.35it/s] 15%|â–ˆâ–Œ        | 152/1000 [01:02<05:51,  2.41it/s] 15%|â–ˆâ–Œ        | 153/1000 [01:02<05:36,  2.52it/s] 15%|â–ˆâ–Œ        | 154/1000 [01:03<05:36,  2.51it/s] 16%|â–ˆâ–Œ        | 155/1000 [01:03<05:36,  2.51it/s] 16%|â–ˆâ–Œ        | 156/1000 [01:04<05:45,  2.45it/s] 16%|â–ˆâ–Œ        | 157/1000 [01:04<05:51,  2.40it/s] 16%|â–ˆâ–Œ        | 158/1000 [01:04<05:35,  2.51it/s] 16%|â–ˆâ–Œ        | 159/1000 [01:05<05:34,  2.51it/s] 16%|â–ˆâ–Œ        | 160/1000 [01:05<05:35,  2.51it/s]                                                   16%|â–ˆâ–Œ        | 160/1000 [01:05<05:35,  2.51it/s] 16%|â–ˆâ–Œ        | 161/1000 [01:06<05:44,  2.43it/s] 16%|â–ˆâ–Œ        | 162/1000 [01:06<05:50,  2.39it/s] 16%|â–ˆâ–‹        | 163/1000 [01:07<05:54,  2.36it/s] 16%|â–ˆâ–‹        | 164/1000 [01:07<05:55,  2.35it/s] 16%|â–ˆâ–‹        | 165/1000 [01:07<05:56,  2.34it/s] 17%|â–ˆâ–‹        | 166/1000 [01:08<05:46,  2.41it/s] 17%|â–ˆâ–‹        | 167/1000 [01:08<05:49,  2.38it/s] 17%|â–ˆâ–‹        | 168/1000 [01:09<05:43,  2.42it/s] 17%|â–ˆâ–‹        | 169/1000 [01:09<05:37,  2.46it/s] 17%|â–ˆâ–‹        | 170/1000 [01:09<05:34,  2.48it/s]                                                   17%|â–ˆâ–‹        | 170/1000 [01:09<05:34,  2.48it/s] 17%|â–ˆâ–‹        | 171/1000 [01:10<05:25,  2.54it/s] 17%|â–ˆâ–‹        | 172/1000 [01:10<05:27,  2.53it/s] 17%|â–ˆâ–‹        | 173/1000 [01:11<05:52,  2.34it/s] 17%|â–ˆâ–‹        | 174/1000 [01:11<05:45,  2.39it/s] 18%|â–ˆâ–Š        | 175/1000 [01:12<05:40,  2.43it/s] 18%|â–ˆâ–Š        | 176/1000 [01:12<05:36,  2.45it/s] 18%|â–ˆâ–Š        | 177/1000 [01:12<05:43,  2.40it/s] 18%|â–ˆâ–Š        | 178/1000 [01:13<05:37,  2.44it/s] 18%|â–ˆâ–Š        | 179/1000 [01:13<05:33,  2.46it/s] 18%|â–ˆâ–Š        | 180/1000 [01:14<05:22,  2.54it/s]                                                   18%|â–ˆâ–Š        | 180/1000 [01:14<05:22,  2.54it/s] 18%|â–ˆâ–Š        | 181/1000 [01:14<05:31,  2.47it/s] 18%|â–ˆâ–Š        | 182/1000 [01:14<05:28,  2.49it/s] 18%|â–ˆâ–Š        | 183/1000 [01:15<05:27,  2.49it/s] 18%|â–ˆâ–Š        | 184/1000 [01:15<05:26,  2.50it/s] 18%|â–ˆâ–Š        | 185/1000 [01:15<05:16,  2.57it/s] 19%|â–ˆâ–Š        | 186/1000 [01:16<05:18,  2.56it/s] 19%|â–ˆâ–Š        | 187/1000 [01:16<05:27,  2.48it/s] 19%|â–ˆâ–‰        | 188/1000 [01:17<05:25,  2.49it/s] 19%|â–ˆâ–‰        | 189/1000 [01:17<05:24,  2.50it/s] 19%|â–ˆâ–‰        | 190/1000 [01:18<05:23,  2.50it/s]                                                   19%|â–ˆâ–‰        | 190/1000 [01:18<05:23,  2.50it/s] 19%|â–ˆâ–‰        | 191/1000 [01:18<05:31,  2.44it/s] 19%|â–ˆâ–‰        | 192/1000 [01:18<05:36,  2.40it/s] 19%|â–ˆâ–‰        | 193/1000 [01:19<05:31,  2.43it/s] 19%|â–ˆâ–‰        | 194/1000 [01:19<05:19,  2.53it/s] 20%|â–ˆâ–‰        | 195/1000 [01:20<05:11,  2.58it/s] 20%|â–ˆâ–‰        | 196/1000 [01:20<05:23,  2.49it/s] 20%|â–ˆâ–‰        | 197/1000 [01:20<05:22,  2.49it/s] 20%|â–ˆâ–‰        | 198/1000 [01:21<05:30,  2.43it/s] 20%|â–ˆâ–‰        | 199/1000 [01:21<05:59,  2.23it/s] 20%|â–ˆâ–ˆ        | 200/1000 [01:22<05:54,  2.25it/s]                                                   20%|â–ˆâ–ˆ        | 200/1000 [01:22<05:54,  2.25it/s]Saving model checkpoint to ./output/checkpoint-200
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 20%|â–ˆâ–ˆ        | 201/1000 [01:22<06:06,  2.18it/s] 20%|â–ˆâ–ˆ        | 202/1000 [01:23<06:00,  2.21it/s] 20%|â–ˆâ–ˆ        | 203/1000 [01:23<05:47,  2.30it/s] 20%|â–ˆâ–ˆ        | 204/1000 [01:23<05:38,  2.35it/s] 20%|â–ˆâ–ˆ        | 205/1000 [01:24<05:30,  2.41it/s] 21%|â–ˆâ–ˆ        | 206/1000 [01:24<05:24,  2.45it/s] 21%|â–ˆâ–ˆ        | 207/1000 [01:25<05:30,  2.40it/s] 21%|â–ˆâ–ˆ        | 208/1000 [01:25<05:33,  2.37it/s] 21%|â–ˆâ–ˆ        | 209/1000 [01:26<05:24,  2.43it/s] 21%|â–ˆâ–ˆ        | 210/1000 [01:26<05:21,  2.46it/s]                                                   21%|â–ˆâ–ˆ        | 210/1000 [01:26<05:21,  2.46it/s] 21%|â–ˆâ–ˆ        | 211/1000 [01:26<05:16,  2.50it/s] 21%|â–ˆâ–ˆ        | 212/1000 [01:27<04:54,  2.68it/s] 21%|â–ˆâ–ˆâ–       | 213/1000 [01:27<04:58,  2.64it/s] 21%|â–ˆâ–ˆâ–       | 214/1000 [01:27<05:10,  2.53it/s] 22%|â–ˆâ–ˆâ–       | 215/1000 [01:28<05:07,  2.55it/s] 22%|â–ˆâ–ˆâ–       | 216/1000 [01:28<05:08,  2.54it/s] 22%|â–ˆâ–ˆâ–       | 217/1000 [01:29<05:09,  2.53it/s] 22%|â–ˆâ–ˆâ–       | 218/1000 [01:29<05:17,  2.46it/s] 22%|â–ˆâ–ˆâ–       | 219/1000 [01:29<05:06,  2.55it/s] 22%|â–ˆâ–ˆâ–       | 220/1000 [01:30<05:07,  2.53it/s]                                                   22%|â–ˆâ–ˆâ–       | 220/1000 [01:30<05:07,  2.53it/s] 22%|â–ˆâ–ˆâ–       | 221/1000 [01:30<05:15,  2.47it/s] 22%|â–ˆâ–ˆâ–       | 222/1000 [01:31<05:14,  2.47it/s] 22%|â–ˆâ–ˆâ–       | 223/1000 [01:31<05:40,  2.28it/s] 22%|â–ˆâ–ˆâ–       | 224/1000 [01:32<05:38,  2.30it/s] 22%|â–ˆâ–ˆâ–Ž       | 225/1000 [01:32<05:21,  2.41it/s] 23%|â–ˆâ–ˆâ–Ž       | 226/1000 [01:32<05:16,  2.45it/s] 23%|â–ˆâ–ˆâ–Ž       | 227/1000 [01:33<05:03,  2.55it/s] 23%|â–ˆâ–ˆâ–Ž       | 228/1000 [01:33<04:55,  2.61it/s] 23%|â–ˆâ–ˆâ–Ž       | 229/1000 [01:33<04:58,  2.58it/s] 23%|â–ˆâ–ˆâ–Ž       | 230/1000 [01:34<04:53,  2.62it/s]                                                   23%|â–ˆâ–ˆâ–Ž       | 230/1000 [01:34<04:53,  2.62it/s] 23%|â–ˆâ–ˆâ–Ž       | 231/1000 [01:34<04:57,  2.59it/s] 23%|â–ˆâ–ˆâ–Ž       | 232/1000 [01:35<04:57,  2.58it/s] 23%|â–ˆâ–ˆâ–Ž       | 233/1000 [01:35<04:59,  2.56it/s] 23%|â–ˆâ–ˆâ–Ž       | 234/1000 [01:35<04:50,  2.63it/s] 24%|â–ˆâ–ˆâ–Ž       | 235/1000 [01:36<04:56,  2.58it/s] 24%|â–ˆâ–ˆâ–Ž       | 236/1000 [01:36<04:59,  2.55it/s] 24%|â–ˆâ–ˆâ–Ž       | 237/1000 [01:37<05:02,  2.52it/s] 24%|â–ˆâ–ˆâ–       | 238/1000 [01:37<05:00,  2.53it/s] 24%|â–ˆâ–ˆâ–       | 239/1000 [01:37<05:09,  2.46it/s] 24%|â–ˆâ–ˆâ–       | 240/1000 [01:38<05:07,  2.47it/s]                                                   24%|â–ˆâ–ˆâ–       | 240/1000 [01:38<05:07,  2.47it/s] 24%|â–ˆâ–ˆâ–       | 241/1000 [01:38<05:05,  2.49it/s] 24%|â–ˆâ–ˆâ–       | 242/1000 [01:39<04:53,  2.58it/s] 24%|â–ˆâ–ˆâ–       | 243/1000 [01:39<04:55,  2.56it/s] 24%|â–ˆâ–ˆâ–       | 244/1000 [01:39<05:05,  2.48it/s] 24%|â–ˆâ–ˆâ–       | 245/1000 [01:40<05:37,  2.24it/s] 25%|â–ˆâ–ˆâ–       | 246/1000 [01:40<05:24,  2.32it/s] 25%|â–ˆâ–ˆâ–       | 247/1000 [01:41<05:09,  2.43it/s] 25%|â–ˆâ–ˆâ–       | 248/1000 [01:41<05:05,  2.47it/s] 25%|â–ˆâ–ˆâ–       | 249/1000 [01:41<05:02,  2.49it/s] 25%|â–ˆâ–ˆâ–Œ       | 250/1000 [01:42<05:00,  2.50it/s]                                                   25%|â–ˆâ–ˆâ–Œ       | 250/1000 [01:42<05:00,  2.50it/s]Saving model checkpoint to ./output/checkpoint-250
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 25%|â–ˆâ–ˆâ–Œ       | 251/1000 [01:42<05:20,  2.33it/s] 25%|â–ˆâ–ˆâ–Œ       | 252/1000 [01:43<05:20,  2.33it/s] 25%|â–ˆâ–ˆâ–Œ       | 253/1000 [01:43<05:03,  2.46it/s] 25%|â–ˆâ–ˆâ–Œ       | 254/1000 [01:44<05:09,  2.41it/s] 26%|â–ˆâ–ˆâ–Œ       | 255/1000 [01:44<05:13,  2.37it/s] 26%|â–ˆâ–ˆâ–Œ       | 256/1000 [01:44<04:58,  2.49it/s] 26%|â–ˆâ–ˆâ–Œ       | 257/1000 [01:45<04:47,  2.58it/s] 26%|â–ˆâ–ˆâ–Œ       | 258/1000 [01:45<04:40,  2.65it/s] 26%|â–ˆâ–ˆâ–Œ       | 259/1000 [01:46<04:52,  2.54it/s] 26%|â–ˆâ–ˆâ–Œ       | 260/1000 [01:46<04:53,  2.52it/s]                                                   26%|â–ˆâ–ˆâ–Œ       | 260/1000 [01:46<04:53,  2.52it/s] 26%|â–ˆâ–ˆâ–Œ       | 261/1000 [01:46<04:59,  2.46it/s] 26%|â–ˆâ–ˆâ–Œ       | 262/1000 [01:47<05:04,  2.42it/s] 26%|â–ˆâ–ˆâ–‹       | 263/1000 [01:47<04:59,  2.46it/s] 26%|â–ˆâ–ˆâ–‹       | 264/1000 [01:48<04:56,  2.48it/s] 26%|â–ˆâ–ˆâ–‹       | 265/1000 [01:48<04:45,  2.58it/s] 27%|â–ˆâ–ˆâ–‹       | 266/1000 [01:48<04:55,  2.48it/s] 27%|â–ˆâ–ˆâ–‹       | 267/1000 [01:49<04:52,  2.50it/s] 27%|â–ˆâ–ˆâ–‹       | 268/1000 [01:49<05:21,  2.27it/s] 27%|â–ˆâ–ˆâ–‹       | 269/1000 [01:50<05:12,  2.34it/s] 27%|â–ˆâ–ˆâ–‹       | 270/1000 [01:50<05:06,  2.38it/s]                                                   27%|â–ˆâ–ˆâ–‹       | 270/1000 [01:50<05:06,  2.38it/s] 27%|â–ˆâ–ˆâ–‹       | 271/1000 [01:51<05:08,  2.36it/s] 27%|â–ˆâ–ˆâ–‹       | 272/1000 [01:51<05:01,  2.41it/s] 27%|â–ˆâ–ˆâ–‹       | 273/1000 [01:51<04:57,  2.44it/s] 27%|â–ˆâ–ˆâ–‹       | 274/1000 [01:52<04:47,  2.53it/s] 28%|â–ˆâ–ˆâ–Š       | 275/1000 [01:52<04:47,  2.52it/s] 28%|â–ˆâ–ˆâ–Š       | 276/1000 [01:52<04:46,  2.53it/s] 28%|â–ˆâ–ˆâ–Š       | 277/1000 [01:53<04:36,  2.61it/s] 28%|â–ˆâ–ˆâ–Š       | 278/1000 [01:53<04:31,  2.66it/s] 28%|â–ˆâ–ˆâ–Š       | 279/1000 [01:54<04:44,  2.54it/s] 28%|â–ˆâ–ˆâ–Š       | 280/1000 [01:54<04:42,  2.54it/s]                                                   28%|â–ˆâ–ˆâ–Š       | 280/1000 [01:54<04:42,  2.54it/s] 28%|â–ˆâ–ˆâ–Š       | 281/1000 [01:54<04:51,  2.47it/s] 28%|â–ˆâ–ˆâ–Š       | 282/1000 [01:55<04:56,  2.42it/s] 28%|â–ˆâ–ˆâ–Š       | 283/1000 [01:55<05:00,  2.39it/s] 28%|â–ˆâ–ˆâ–Š       | 284/1000 [01:56<04:54,  2.43it/s] 28%|â–ˆâ–ˆâ–Š       | 285/1000 [01:56<04:50,  2.46it/s] 29%|â–ˆâ–ˆâ–Š       | 286/1000 [01:56<04:47,  2.49it/s] 29%|â–ˆâ–ˆâ–Š       | 287/1000 [01:57<04:44,  2.51it/s] 29%|â–ˆâ–ˆâ–‰       | 288/1000 [01:57<04:44,  2.51it/s] 29%|â–ˆâ–ˆâ–‰       | 289/1000 [01:58<04:34,  2.59it/s] 29%|â–ˆâ–ˆâ–‰       | 290/1000 [01:58<04:26,  2.66it/s]                                                   29%|â–ˆâ–ˆâ–‰       | 290/1000 [01:58<04:26,  2.66it/s] 29%|â–ˆâ–ˆâ–‰       | 291/1000 [01:58<04:31,  2.61it/s] 29%|â–ˆâ–ˆâ–‰       | 292/1000 [01:59<04:42,  2.51it/s] 29%|â–ˆâ–ˆâ–‰       | 293/1000 [01:59<04:41,  2.52it/s] 29%|â–ˆâ–ˆâ–‰       | 294/1000 [02:00<05:06,  2.30it/s] 30%|â–ˆâ–ˆâ–‰       | 295/1000 [02:00<04:56,  2.38it/s] 30%|â–ˆâ–ˆâ–‰       | 296/1000 [02:01<04:50,  2.42it/s] 30%|â–ˆâ–ˆâ–‰       | 297/1000 [02:01<04:46,  2.46it/s] 30%|â–ˆâ–ˆâ–‰       | 298/1000 [02:01<04:44,  2.47it/s] 30%|â–ˆâ–ˆâ–‰       | 299/1000 [02:02<04:42,  2.48it/s] 30%|â–ˆâ–ˆâ–ˆ       | 300/1000 [02:02<04:22,  2.66it/s]                                                   30%|â–ˆâ–ˆâ–ˆ       | 300/1000 [02:02<04:22,  2.66it/s]Saving model checkpoint to ./output/checkpoint-300
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 30%|â–ˆâ–ˆâ–ˆ       | 301/1000 [02:02<04:39,  2.50it/s] 30%|â–ˆâ–ˆâ–ˆ       | 302/1000 [02:03<04:39,  2.50it/s] 30%|â–ˆâ–ˆâ–ˆ       | 303/1000 [02:03<04:36,  2.52it/s] 30%|â–ˆâ–ˆâ–ˆ       | 304/1000 [02:04<04:37,  2.51it/s] 30%|â–ˆâ–ˆâ–ˆ       | 305/1000 [02:04<04:34,  2.53it/s] 31%|â–ˆâ–ˆâ–ˆ       | 306/1000 [02:04<04:42,  2.45it/s] 31%|â–ˆâ–ˆâ–ˆ       | 307/1000 [02:05<04:31,  2.55it/s] 31%|â–ˆâ–ˆâ–ˆ       | 308/1000 [02:05<04:25,  2.60it/s] 31%|â–ˆâ–ˆâ–ˆ       | 309/1000 [02:06<04:36,  2.50it/s] 31%|â–ˆâ–ˆâ–ˆ       | 310/1000 [02:06<04:36,  2.50it/s]                                                   31%|â–ˆâ–ˆâ–ˆ       | 310/1000 [02:06<04:36,  2.50it/s] 31%|â–ˆâ–ˆâ–ˆ       | 311/1000 [02:06<04:31,  2.54it/s] 31%|â–ˆâ–ˆâ–ˆ       | 312/1000 [02:07<04:33,  2.51it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 313/1000 [02:07<04:29,  2.55it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 314/1000 [02:08<04:37,  2.47it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 315/1000 [02:08<04:35,  2.48it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 316/1000 [02:08<04:32,  2.51it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 317/1000 [02:09<04:49,  2.36it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 318/1000 [02:09<04:50,  2.34it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 319/1000 [02:10<04:51,  2.34it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 320/1000 [02:10<04:46,  2.38it/s]                                                   32%|â–ˆâ–ˆâ–ˆâ–      | 320/1000 [02:10<04:46,  2.38it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 321/1000 [02:11<04:40,  2.42it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 322/1000 [02:11<04:37,  2.45it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 323/1000 [02:11<04:34,  2.46it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 324/1000 [02:12<04:32,  2.48it/s] 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 325/1000 [02:12<04:31,  2.49it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 326/1000 [02:13<04:39,  2.41it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 327/1000 [02:13<04:36,  2.44it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 328/1000 [02:13<04:33,  2.46it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 329/1000 [02:14<04:31,  2.47it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330/1000 [02:14<04:29,  2.48it/s]                                                   33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330/1000 [02:14<04:29,  2.48it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 331/1000 [02:15<04:35,  2.43it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332/1000 [02:15<04:39,  2.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 333/1000 [02:16<04:42,  2.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 334/1000 [02:16<04:31,  2.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 335/1000 [02:16<04:27,  2.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 336/1000 [02:17<04:26,  2.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 337/1000 [02:17<04:24,  2.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 338/1000 [02:17<04:24,  2.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 339/1000 [02:18<04:45,  2.32it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 340/1000 [02:18<04:36,  2.38it/s]                                                   34%|â–ˆâ–ˆâ–ˆâ–      | 340/1000 [02:18<04:36,  2.38it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 341/1000 [02:19<04:14,  2.59it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 342/1000 [02:19<04:16,  2.57it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 343/1000 [02:19<04:09,  2.63it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 344/1000 [02:20<04:12,  2.60it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 345/1000 [02:20<04:05,  2.67it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 346/1000 [02:21<04:08,  2.63it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 347/1000 [02:21<04:10,  2.61it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 348/1000 [02:21<04:12,  2.58it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 349/1000 [02:22<04:14,  2.56it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350/1000 [02:22<04:08,  2.62it/s]                                                   35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350/1000 [02:22<04:08,  2.62it/s]Saving model checkpoint to ./output/checkpoint-350
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 351/1000 [02:23<04:19,  2.50it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 352/1000 [02:23<04:25,  2.44it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353/1000 [02:23<04:21,  2.47it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 354/1000 [02:24<04:18,  2.50it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 355/1000 [02:24<04:16,  2.52it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 356/1000 [02:25<04:14,  2.53it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 357/1000 [02:25<04:14,  2.53it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358/1000 [02:25<04:08,  2.58it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 359/1000 [02:26<04:03,  2.63it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360/1000 [02:26<04:06,  2.60it/s]                                                   36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360/1000 [02:26<04:06,  2.60it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 361/1000 [02:27<04:16,  2.49it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 362/1000 [02:27<04:09,  2.56it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 363/1000 [02:27<04:39,  2.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 364/1000 [02:28<04:37,  2.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 365/1000 [02:28<04:35,  2.30it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 366/1000 [02:29<04:27,  2.37it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 367/1000 [02:29<04:15,  2.48it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 368/1000 [02:29<04:09,  2.54it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 369/1000 [02:30<04:09,  2.53it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 370/1000 [02:30<04:04,  2.57it/s]                                                   37%|â–ˆâ–ˆâ–ˆâ–‹      | 370/1000 [02:30<04:04,  2.57it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 371/1000 [02:31<04:06,  2.55it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 372/1000 [02:31<04:08,  2.53it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 373/1000 [02:31<04:14,  2.46it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 374/1000 [02:32<04:12,  2.48it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 375/1000 [02:32<04:12,  2.48it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376/1000 [02:33<04:11,  2.48it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 377/1000 [02:33<04:04,  2.55it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 378/1000 [02:33<04:00,  2.58it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 379/1000 [02:34<04:13,  2.45it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 380/1000 [02:34<04:19,  2.39it/s]                                                   38%|â–ˆâ–ˆâ–ˆâ–Š      | 380/1000 [02:34<04:19,  2.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 381/1000 [02:35<04:16,  2.41it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 382/1000 [02:35<04:23,  2.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 383/1000 [02:36<04:18,  2.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384/1000 [02:36<04:24,  2.33it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 385/1000 [02:36<04:20,  2.36it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 386/1000 [02:37<04:16,  2.39it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 387/1000 [02:37<04:14,  2.41it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 388/1000 [02:38<04:18,  2.37it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 389/1000 [02:38<04:40,  2.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 390/1000 [02:39<04:31,  2.24it/s]                                                   39%|â–ˆâ–ˆâ–ˆâ–‰      | 390/1000 [02:39<04:31,  2.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 391/1000 [02:39<04:21,  2.33it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 392/1000 [02:39<04:23,  2.31it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 393/1000 [02:40<04:15,  2.38it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 394/1000 [02:40<04:03,  2.49it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 395/1000 [02:41<04:00,  2.52it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 396/1000 [02:41<04:05,  2.46it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 397/1000 [02:41<03:56,  2.55it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 398/1000 [02:42<03:57,  2.53it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399/1000 [02:42<03:52,  2.58it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 400/1000 [02:43<04:01,  2.49it/s]                                                   40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 400/1000 [02:43<04:01,  2.49it/s]Saving model checkpoint to ./output/checkpoint-400
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 401/1000 [02:43<04:10,  2.39it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 402/1000 [02:43<04:00,  2.49it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 403/1000 [02:44<03:59,  2.49it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 404/1000 [02:44<03:57,  2.51it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 405/1000 [02:45<03:57,  2.50it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 406/1000 [02:45<03:58,  2.49it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407/1000 [02:45<03:58,  2.49it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 408/1000 [02:46<04:03,  2.43it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 409/1000 [02:46<04:02,  2.44it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 410/1000 [02:47<04:01,  2.45it/s]                                                   41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 410/1000 [02:47<04:01,  2.45it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 411/1000 [02:47<04:00,  2.45it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 412/1000 [02:47<04:00,  2.45it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 413/1000 [02:48<04:24,  2.22it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 414/1000 [02:48<04:12,  2.32it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 415/1000 [02:49<04:04,  2.39it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 416/1000 [02:49<04:00,  2.43it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 417/1000 [02:50<03:57,  2.45it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 418/1000 [02:50<03:49,  2.54it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 419/1000 [02:50<03:55,  2.47it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 420/1000 [02:51<03:52,  2.49it/s]                                                   42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 420/1000 [02:51<03:52,  2.49it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 421/1000 [02:51<03:51,  2.50it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422/1000 [02:52<03:44,  2.58it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 423/1000 [02:52<03:43,  2.58it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 424/1000 [02:52<03:45,  2.55it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 425/1000 [02:53<03:52,  2.47it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 426/1000 [02:53<03:56,  2.42it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427/1000 [02:54<03:53,  2.45it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 428/1000 [02:54<03:59,  2.39it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 429/1000 [02:54<04:00,  2.37it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430/1000 [02:55<03:54,  2.43it/s]                                                   43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430/1000 [02:55<03:54,  2.43it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 431/1000 [02:55<03:51,  2.45it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 432/1000 [02:56<03:56,  2.41it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 433/1000 [02:56<03:44,  2.52it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 434/1000 [02:56<03:43,  2.53it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 435/1000 [02:57<04:01,  2.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 436/1000 [02:57<03:56,  2.39it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 437/1000 [02:58<03:52,  2.42it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 438/1000 [02:58<03:42,  2.52it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 439/1000 [02:58<03:42,  2.52it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440/1000 [02:59<03:41,  2.52it/s]                                                   44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440/1000 [02:59<03:41,  2.52it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 441/1000 [02:59<03:26,  2.70it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 442/1000 [03:00<03:31,  2.64it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 443/1000 [03:00<03:32,  2.62it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 444/1000 [03:00<03:33,  2.61it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445/1000 [03:01<03:33,  2.60it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 446/1000 [03:01<03:35,  2.57it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 447/1000 [03:02<03:43,  2.47it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448/1000 [03:02<03:42,  2.48it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 449/1000 [03:02<03:34,  2.57it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 450/1000 [03:03<03:35,  2.56it/s]                                                   45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 450/1000 [03:03<03:35,  2.56it/s]Saving model checkpoint to ./output/checkpoint-450
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 451/1000 [03:03<03:54,  2.34it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 452/1000 [03:04<03:54,  2.33it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453/1000 [03:04<03:43,  2.45it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 454/1000 [03:04<03:42,  2.46it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 455/1000 [03:05<03:34,  2.54it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 456/1000 [03:05<03:41,  2.46it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 457/1000 [03:06<03:33,  2.55it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 458/1000 [03:06<03:39,  2.47it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 459/1000 [03:06<03:37,  2.48it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460/1000 [03:07<03:36,  2.49it/s]                                                   46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460/1000 [03:07<03:36,  2.49it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 461/1000 [03:07<03:56,  2.28it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 462/1000 [03:08<03:44,  2.40it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463/1000 [03:08<03:39,  2.45it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 464/1000 [03:09<03:38,  2.46it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465/1000 [03:09<03:36,  2.47it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 466/1000 [03:09<03:34,  2.49it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 467/1000 [03:10<03:25,  2.59it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 468/1000 [03:10<03:32,  2.50it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 469/1000 [03:10<03:31,  2.51it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 470/1000 [03:11<03:31,  2.51it/s]                                                   47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 470/1000 [03:11<03:31,  2.51it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 471/1000 [03:11<03:24,  2.58it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 472/1000 [03:12<03:25,  2.56it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473/1000 [03:12<03:26,  2.55it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 474/1000 [03:12<03:22,  2.60it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 475/1000 [03:13<03:29,  2.50it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476/1000 [03:13<03:28,  2.51it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 477/1000 [03:14<03:28,  2.51it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 478/1000 [03:14<03:27,  2.51it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 479/1000 [03:14<03:27,  2.52it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 480/1000 [03:15<03:26,  2.52it/s]                                                   48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 480/1000 [03:15<03:26,  2.52it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481/1000 [03:15<03:25,  2.53it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 482/1000 [03:16<03:30,  2.46it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483/1000 [03:16<03:29,  2.47it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 484/1000 [03:16<03:26,  2.50it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 485/1000 [03:17<03:40,  2.34it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 486/1000 [03:17<03:34,  2.39it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 487/1000 [03:18<03:30,  2.44it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 488/1000 [03:18<03:33,  2.40it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 489/1000 [03:19<03:35,  2.37it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 490/1000 [03:19<03:36,  2.35it/s]                                                   49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 490/1000 [03:19<03:36,  2.35it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491/1000 [03:19<03:37,  2.34it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 492/1000 [03:20<03:26,  2.46it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 493/1000 [03:20<03:10,  2.65it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 494/1000 [03:21<03:19,  2.54it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 495/1000 [03:21<03:17,  2.55it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 496/1000 [03:21<03:18,  2.54it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 497/1000 [03:22<03:11,  2.63it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 498/1000 [03:22<03:19,  2.52it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499/1000 [03:22<03:18,  2.52it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 500/1000 [03:23<03:18,  2.52it/s]                                                   50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 500/1000 [03:23<03:18,  2.52it/s]Saving model checkpoint to ./output/checkpoint-500
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501/1000 [03:23<03:34,  2.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 502/1000 [03:24<03:23,  2.45it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 503/1000 [03:24<03:17,  2.52it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 504/1000 [03:25<03:17,  2.52it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 505/1000 [03:25<03:22,  2.44it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506/1000 [03:25<03:21,  2.46it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 507/1000 [03:26<03:19,  2.48it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 508/1000 [03:26<03:40,  2.24it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 509/1000 [03:27<03:31,  2.33it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 510/1000 [03:27<03:30,  2.32it/s]                                                   51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 510/1000 [03:27<03:30,  2.32it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 511/1000 [03:28<03:30,  2.32it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512/1000 [03:28<03:25,  2.37it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 513/1000 [03:28<03:20,  2.43it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514/1000 [03:29<03:17,  2.46it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 515/1000 [03:29<03:16,  2.47it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 516/1000 [03:30<03:19,  2.42it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517/1000 [03:30<03:16,  2.46it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 518/1000 [03:30<03:14,  2.48it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 519/1000 [03:31<03:13,  2.49it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 520/1000 [03:31<03:11,  2.50it/s]                                                   52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 520/1000 [03:31<03:11,  2.50it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 521/1000 [03:32<03:11,  2.50it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522/1000 [03:32<03:10,  2.51it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 523/1000 [03:32<03:03,  2.60it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 524/1000 [03:33<02:58,  2.66it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 525/1000 [03:33<03:00,  2.64it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 526/1000 [03:33<03:03,  2.59it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 527/1000 [03:34<03:10,  2.48it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 528/1000 [03:34<03:09,  2.49it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529/1000 [03:35<03:07,  2.51it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 530/1000 [03:35<03:25,  2.29it/s]                                                   53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 530/1000 [03:35<03:25,  2.29it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 531/1000 [03:36<03:23,  2.30it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532/1000 [03:36<03:16,  2.38it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 533/1000 [03:36<03:13,  2.42it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 534/1000 [03:37<03:15,  2.39it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 535/1000 [03:37<03:05,  2.51it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 536/1000 [03:38<03:05,  2.51it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 537/1000 [03:38<03:04,  2.50it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 538/1000 [03:38<03:04,  2.50it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 539/1000 [03:39<02:59,  2.57it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 540/1000 [03:39<03:06,  2.47it/s]                                                   54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 540/1000 [03:39<03:06,  2.47it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 541/1000 [03:40<03:06,  2.47it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 542/1000 [03:40<03:00,  2.54it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 543/1000 [03:40<02:54,  2.61it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 544/1000 [03:41<02:55,  2.59it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545/1000 [03:41<03:01,  2.50it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 546/1000 [03:42<03:06,  2.44it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 547/1000 [03:42<03:04,  2.46it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 548/1000 [03:42<03:01,  2.49it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 549/1000 [03:43<03:05,  2.43it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550/1000 [03:43<03:02,  2.46it/s]                                                   55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550/1000 [03:43<03:02,  2.46it/s]Saving model checkpoint to ./output/checkpoint-550
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 551/1000 [03:44<03:09,  2.36it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552/1000 [03:44<03:05,  2.41it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 553/1000 [03:44<02:58,  2.51it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 554/1000 [03:45<02:56,  2.52it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 555/1000 [03:45<02:55,  2.53it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 556/1000 [03:46<03:11,  2.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 557/1000 [03:46<03:01,  2.44it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 558/1000 [03:46<02:58,  2.48it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 559/1000 [03:47<03:02,  2.41it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560/1000 [03:47<02:48,  2.61it/s]                                                   56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560/1000 [03:47<02:48,  2.61it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 561/1000 [03:48<02:47,  2.63it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 562/1000 [03:48<02:50,  2.57it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 563/1000 [03:48<02:51,  2.54it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 564/1000 [03:49<02:53,  2.51it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 565/1000 [03:49<02:53,  2.50it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 566/1000 [03:50<02:59,  2.42it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 567/1000 [03:50<03:01,  2.38it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568/1000 [03:51<03:03,  2.35it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 569/1000 [03:51<02:59,  2.40it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570/1000 [03:51<02:56,  2.44it/s]                                                   57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570/1000 [03:51<02:56,  2.44it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 571/1000 [03:52<02:59,  2.39it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 572/1000 [03:52<02:50,  2.51it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 573/1000 [03:53<02:49,  2.52it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 574/1000 [03:53<02:49,  2.52it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 575/1000 [03:53<02:54,  2.44it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 576/1000 [03:54<02:52,  2.45it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 577/1000 [03:54<02:50,  2.48it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 578/1000 [03:55<02:45,  2.55it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 579/1000 [03:55<02:45,  2.55it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 580/1000 [03:55<02:55,  2.40it/s]                                                   58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 580/1000 [03:55<02:55,  2.40it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 581/1000 [03:56<02:56,  2.37it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 582/1000 [03:56<02:53,  2.41it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583/1000 [03:57<02:45,  2.53it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 584/1000 [03:57<02:43,  2.54it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 585/1000 [03:57<02:48,  2.47it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 586/1000 [03:58<02:47,  2.48it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 587/1000 [03:58<02:41,  2.56it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 588/1000 [03:59<02:46,  2.48it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 589/1000 [03:59<02:45,  2.48it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 590/1000 [03:59<02:33,  2.67it/s]                                                   59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 590/1000 [03:59<02:33,  2.67it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591/1000 [04:00<02:40,  2.55it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 592/1000 [04:00<02:45,  2.47it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 593/1000 [04:01<02:38,  2.56it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 594/1000 [04:01<02:39,  2.54it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 595/1000 [04:01<02:35,  2.60it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 596/1000 [04:02<02:41,  2.50it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 597/1000 [04:02<02:37,  2.56it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 598/1000 [04:02<02:38,  2.54it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599/1000 [04:03<02:38,  2.54it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 600/1000 [04:03<02:37,  2.53it/s]                                                   60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 600/1000 [04:03<02:37,  2.53it/s]Saving model checkpoint to ./output/checkpoint-600
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601/1000 [04:04<02:41,  2.47it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 602/1000 [04:04<02:54,  2.27it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 603/1000 [04:05<02:49,  2.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604/1000 [04:05<02:45,  2.40it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 605/1000 [04:05<02:42,  2.43it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606/1000 [04:06<02:44,  2.39it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 607/1000 [04:06<02:46,  2.36it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 608/1000 [04:07<02:43,  2.40it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 609/1000 [04:07<02:44,  2.37it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 610/1000 [04:08<02:41,  2.41it/s]                                                   61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 610/1000 [04:08<02:41,  2.41it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 611/1000 [04:08<02:35,  2.50it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 612/1000 [04:08<02:34,  2.51it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 613/1000 [04:09<02:33,  2.52it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614/1000 [04:09<02:33,  2.51it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 615/1000 [04:09<02:33,  2.50it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 616/1000 [04:10<02:32,  2.51it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 617/1000 [04:10<02:36,  2.45it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 618/1000 [04:11<02:29,  2.56it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 619/1000 [04:11<02:29,  2.55it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 620/1000 [04:11<02:29,  2.54it/s]                                                   62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 620/1000 [04:11<02:29,  2.54it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 621/1000 [04:12<02:34,  2.45it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622/1000 [04:12<02:32,  2.48it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 623/1000 [04:13<02:35,  2.42it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624/1000 [04:13<02:45,  2.27it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 625/1000 [04:14<02:44,  2.28it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 626/1000 [04:14<02:39,  2.35it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 627/1000 [04:14<02:31,  2.46it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 628/1000 [04:15<02:34,  2.41it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 629/1000 [04:15<02:31,  2.45it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 630/1000 [04:16<02:29,  2.48it/s]                                                   63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 630/1000 [04:16<02:29,  2.48it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 631/1000 [04:16<02:24,  2.54it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 632/1000 [04:16<02:29,  2.46it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 633/1000 [04:17<02:28,  2.48it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634/1000 [04:17<02:30,  2.42it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 635/1000 [04:18<02:33,  2.38it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 636/1000 [04:18<02:25,  2.50it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637/1000 [04:19<02:30,  2.42it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 638/1000 [04:19<02:28,  2.44it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 639/1000 [04:19<02:37,  2.29it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640/1000 [04:20<02:36,  2.29it/s]                                                   64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640/1000 [04:20<02:36,  2.29it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 641/1000 [04:20<02:36,  2.30it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642/1000 [04:21<02:27,  2.42it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 643/1000 [04:21<02:25,  2.45it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 644/1000 [04:21<02:23,  2.48it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645/1000 [04:22<02:21,  2.51it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 646/1000 [04:22<02:20,  2.53it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 647/1000 [04:23<02:18,  2.54it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 648/1000 [04:23<02:14,  2.62it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 649/1000 [04:23<02:19,  2.52it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650/1000 [04:24<02:19,  2.51it/s]                                                   65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650/1000 [04:24<02:19,  2.51it/s]Saving model checkpoint to ./output/checkpoint-650
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 651/1000 [04:24<02:38,  2.20it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652/1000 [04:25<02:32,  2.28it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 653/1000 [04:25<02:27,  2.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 654/1000 [04:26<02:28,  2.34it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 655/1000 [04:26<02:28,  2.33it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 656/1000 [04:26<02:24,  2.39it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 657/1000 [04:27<02:18,  2.48it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 658/1000 [04:27<02:16,  2.51it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 659/1000 [04:28<02:19,  2.45it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660/1000 [04:28<02:17,  2.48it/s]                                                   66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660/1000 [04:28<02:17,  2.48it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 661/1000 [04:28<02:20,  2.41it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 662/1000 [04:29<02:18,  2.44it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 663/1000 [04:29<02:20,  2.40it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 664/1000 [04:30<02:18,  2.43it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 665/1000 [04:30<02:17,  2.44it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 666/1000 [04:30<02:15,  2.47it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 667/1000 [04:31<02:05,  2.66it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668/1000 [04:31<02:10,  2.54it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 669/1000 [04:32<02:10,  2.54it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670/1000 [04:32<02:10,  2.54it/s]                                                   67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670/1000 [04:32<02:10,  2.54it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 671/1000 [04:32<02:06,  2.60it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 672/1000 [04:33<02:07,  2.57it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673/1000 [04:33<02:04,  2.62it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 674/1000 [04:34<02:04,  2.61it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675/1000 [04:34<02:16,  2.38it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 676/1000 [04:34<02:13,  2.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 677/1000 [04:35<02:12,  2.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678/1000 [04:35<02:14,  2.39it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 679/1000 [04:36<02:22,  2.25it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680/1000 [04:36<02:21,  2.26it/s]                                                   68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680/1000 [04:36<02:21,  2.26it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 681/1000 [04:37<02:17,  2.32it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 682/1000 [04:37<02:13,  2.38it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683/1000 [04:37<02:14,  2.36it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 684/1000 [04:38<02:11,  2.40it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 685/1000 [04:38<02:09,  2.43it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 686/1000 [04:39<02:07,  2.46it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 687/1000 [04:39<02:06,  2.48it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 688/1000 [04:39<02:01,  2.57it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 689/1000 [04:40<02:01,  2.55it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 690/1000 [04:40<02:02,  2.54it/s]                                                   69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 690/1000 [04:40<02:02,  2.54it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691/1000 [04:41<02:05,  2.47it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 692/1000 [04:41<02:04,  2.48it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 693/1000 [04:41<01:59,  2.56it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 694/1000 [04:42<01:59,  2.57it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 695/1000 [04:42<01:58,  2.57it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 696/1000 [04:43<02:02,  2.48it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 697/1000 [04:43<02:17,  2.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698/1000 [04:44<02:11,  2.30it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 699/1000 [04:44<02:08,  2.35it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 700/1000 [04:44<02:01,  2.46it/s]                                                   70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 700/1000 [04:44<02:01,  2.46it/s]Saving model checkpoint to ./output/checkpoint-700
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 701/1000 [04:45<01:58,  2.52it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 702/1000 [04:45<01:57,  2.53it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 703/1000 [04:45<01:56,  2.54it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704/1000 [04:46<01:52,  2.63it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 705/1000 [04:46<01:50,  2.68it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706/1000 [04:47<01:52,  2.62it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 707/1000 [04:47<01:52,  2.60it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 708/1000 [04:47<01:56,  2.50it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 709/1000 [04:48<01:55,  2.51it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 710/1000 [04:48<01:55,  2.52it/s]                                                   71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 710/1000 [04:48<01:55,  2.52it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711/1000 [04:49<01:58,  2.44it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 712/1000 [04:49<01:56,  2.47it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 713/1000 [04:49<01:59,  2.41it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714/1000 [04:50<02:00,  2.37it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 715/1000 [04:50<01:58,  2.41it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 716/1000 [04:51<01:55,  2.46it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 717/1000 [04:51<01:51,  2.54it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 718/1000 [04:52<02:01,  2.33it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 719/1000 [04:52<02:01,  2.31it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 720/1000 [04:52<01:58,  2.37it/s]                                                   72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 720/1000 [04:52<01:58,  2.37it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721/1000 [04:53<01:56,  2.40it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 722/1000 [04:53<01:57,  2.37it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 723/1000 [04:54<01:54,  2.42it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724/1000 [04:54<01:52,  2.46it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 725/1000 [04:54<01:47,  2.57it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 726/1000 [04:55<01:47,  2.55it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 727/1000 [04:55<01:46,  2.55it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 728/1000 [04:56<01:46,  2.55it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729/1000 [04:56<01:46,  2.54it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 730/1000 [04:56<01:43,  2.62it/s]                                                   73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 730/1000 [04:56<01:43,  2.62it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 731/1000 [04:57<01:43,  2.59it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732/1000 [04:57<01:44,  2.57it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 733/1000 [04:57<01:43,  2.57it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 734/1000 [04:58<01:43,  2.56it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 735/1000 [04:58<01:43,  2.56it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 736/1000 [04:59<01:43,  2.55it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 737/1000 [04:59<01:40,  2.62it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 738/1000 [04:59<01:39,  2.64it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 739/1000 [05:00<01:43,  2.52it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 740/1000 [05:00<01:43,  2.51it/s]                                                   74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 740/1000 [05:00<01:43,  2.51it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 741/1000 [05:01<01:39,  2.60it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 742/1000 [05:01<01:43,  2.50it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 743/1000 [05:01<01:42,  2.51it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744/1000 [05:02<01:39,  2.58it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 745/1000 [05:02<01:49,  2.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 746/1000 [05:03<01:46,  2.38it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747/1000 [05:03<01:43,  2.43it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 748/1000 [05:04<01:43,  2.45it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 749/1000 [05:04<01:38,  2.55it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750/1000 [05:04<01:35,  2.63it/s]                                                   75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750/1000 [05:04<01:35,  2.63it/s]Saving model checkpoint to ./output/checkpoint-750
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 751/1000 [05:05<01:38,  2.52it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752/1000 [05:05<01:37,  2.54it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 753/1000 [05:05<01:37,  2.53it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 754/1000 [05:06<01:37,  2.53it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 755/1000 [05:06<01:37,  2.52it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 756/1000 [05:07<01:37,  2.51it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757/1000 [05:07<01:33,  2.59it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 758/1000 [05:07<01:34,  2.57it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 759/1000 [05:08<01:32,  2.62it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760/1000 [05:08<01:32,  2.60it/s]                                                   76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760/1000 [05:08<01:32,  2.60it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 761/1000 [05:09<01:33,  2.56it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 762/1000 [05:09<01:31,  2.61it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 763/1000 [05:09<01:31,  2.58it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 764/1000 [05:10<01:31,  2.58it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765/1000 [05:10<01:29,  2.64it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 766/1000 [05:10<01:27,  2.67it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 767/1000 [05:11<01:31,  2.54it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768/1000 [05:11<01:31,  2.54it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 769/1000 [05:12<01:31,  2.53it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770/1000 [05:12<01:41,  2.27it/s]                                                   77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770/1000 [05:12<01:41,  2.27it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 771/1000 [05:13<01:31,  2.49it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 772/1000 [05:13<01:28,  2.56it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 773/1000 [05:13<01:29,  2.55it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 774/1000 [05:14<01:28,  2.54it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775/1000 [05:14<01:31,  2.47it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 776/1000 [05:15<01:30,  2.47it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 777/1000 [05:15<01:27,  2.55it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778/1000 [05:15<01:27,  2.54it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 779/1000 [05:16<01:30,  2.45it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780/1000 [05:16<01:29,  2.46it/s]                                                   78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780/1000 [05:16<01:29,  2.46it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 781/1000 [05:17<01:29,  2.46it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 782/1000 [05:17<01:28,  2.45it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783/1000 [05:17<01:27,  2.47it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 784/1000 [05:18<01:30,  2.39it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 785/1000 [05:18<01:28,  2.42it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 786/1000 [05:19<01:30,  2.37it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 787/1000 [05:19<01:26,  2.46it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 788/1000 [05:19<01:28,  2.40it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 789/1000 [05:20<01:24,  2.50it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 790/1000 [05:20<01:21,  2.57it/s]                                                   79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 790/1000 [05:20<01:21,  2.57it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 791/1000 [05:21<01:19,  2.64it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 792/1000 [05:21<01:19,  2.62it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 793/1000 [05:21<01:19,  2.59it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 794/1000 [05:22<01:24,  2.43it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 795/1000 [05:22<01:23,  2.45it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796/1000 [05:23<01:24,  2.41it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 797/1000 [05:23<01:25,  2.38it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798/1000 [05:23<01:25,  2.35it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 799/1000 [05:24<01:24,  2.38it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 800/1000 [05:24<01:25,  2.35it/s]                                                   80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 800/1000 [05:24<01:25,  2.35it/s]Saving model checkpoint to ./output/checkpoint-800
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801/1000 [05:25<01:31,  2.18it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 802/1000 [05:25<01:29,  2.22it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 803/1000 [05:26<01:25,  2.30it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 804/1000 [05:26<01:20,  2.42it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 805/1000 [05:26<01:17,  2.50it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806/1000 [05:27<01:14,  2.59it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 807/1000 [05:27<01:14,  2.57it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 808/1000 [05:28<01:15,  2.56it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 809/1000 [05:28<01:16,  2.48it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 810/1000 [05:28<01:16,  2.50it/s]                                                   81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 810/1000 [05:28<01:16,  2.50it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 811/1000 [05:29<01:17,  2.45it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 812/1000 [05:29<01:16,  2.47it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 813/1000 [05:30<01:15,  2.48it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814/1000 [05:30<01:14,  2.51it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 815/1000 [05:30<01:15,  2.45it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 816/1000 [05:31<01:14,  2.47it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 817/1000 [05:31<01:21,  2.25it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 818/1000 [05:32<01:15,  2.40it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 819/1000 [05:32<01:14,  2.44it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 820/1000 [05:32<01:11,  2.52it/s]                                                   82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 820/1000 [05:32<01:11,  2.52it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821/1000 [05:33<01:06,  2.71it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 822/1000 [05:33<01:09,  2.56it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 823/1000 [05:34<01:09,  2.55it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 824/1000 [05:34<01:11,  2.48it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 825/1000 [05:34<01:09,  2.50it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 826/1000 [05:35<01:11,  2.45it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 827/1000 [05:35<01:09,  2.49it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 828/1000 [05:36<01:07,  2.55it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829/1000 [05:36<01:05,  2.62it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 830/1000 [05:36<01:05,  2.58it/s]                                                   83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 830/1000 [05:36<01:05,  2.58it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 831/1000 [05:37<01:05,  2.58it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 832/1000 [05:37<01:05,  2.58it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 833/1000 [05:38<01:03,  2.64it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 834/1000 [05:38<01:05,  2.54it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 835/1000 [05:38<01:03,  2.60it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 836/1000 [05:39<01:01,  2.66it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837/1000 [05:39<01:02,  2.62it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 838/1000 [05:39<01:00,  2.67it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839/1000 [05:40<00:59,  2.72it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 840/1000 [05:40<01:02,  2.58it/s]                                                  {'loss': 1.1672, 'grad_norm': 0.5750606656074524, 'learning_rate': 9.9e-06, 'epoch': 0.0}
{'loss': 1.2242, 'grad_norm': 1.4041211605072021, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.01}
{'loss': 1.4309, 'grad_norm': 0.8295020461082458, 'learning_rate': 9.7e-06, 'epoch': 0.01}
{'loss': 1.4078, 'grad_norm': 1.0180370807647705, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.01}
{'loss': 1.3965, 'grad_norm': 0.8932903409004211, 'learning_rate': 9.5e-06, 'epoch': 0.02}
{'loss': 1.4, 'grad_norm': 0.8970229029655457, 'learning_rate': 9.4e-06, 'epoch': 0.02}
{'loss': 1.473, 'grad_norm': 1.0811915397644043, 'learning_rate': 9.3e-06, 'epoch': 0.03}
{'loss': 1.4309, 'grad_norm': 1.5092614889144897, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.03}
{'loss': 1.1191, 'grad_norm': 1.3466817140579224, 'learning_rate': 9.100000000000001e-06, 'epoch': 0.03}
{'loss': 1.2805, 'grad_norm': 1.2847670316696167, 'learning_rate': 9e-06, 'epoch': 0.04}
{'loss': 1.5203, 'grad_norm': 1.124829649925232, 'learning_rate': 8.900000000000001e-06, 'epoch': 0.04}
{'loss': 1.3945, 'grad_norm': 2.04046630859375, 'learning_rate': 8.8e-06, 'epoch': 0.04}
{'loss': 1.298, 'grad_norm': 1.2887004613876343, 'learning_rate': 8.700000000000001e-06, 'epoch': 0.05}
{'loss': 1.1754, 'grad_norm': 1.1815941333770752, 'learning_rate': 8.6e-06, 'epoch': 0.05}
{'loss': 1.4742, 'grad_norm': 1.7070242166519165, 'learning_rate': 8.5e-06, 'epoch': 0.06}
{'loss': 1.3006, 'grad_norm': 1.1649190187454224, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.06}
{'loss': 1.4074, 'grad_norm': 1.8348442316055298, 'learning_rate': 8.3e-06, 'epoch': 0.06}
{'loss': 1.2184, 'grad_norm': 1.6197775602340698, 'learning_rate': 8.2e-06, 'epoch': 0.07}
{'loss': 1.4004, 'grad_norm': 1.4365527629852295, 'learning_rate': 8.1e-06, 'epoch': 0.07}
{'loss': 1.3854, 'grad_norm': 1.440063714981079, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.07}
{'loss': 1.3402, 'grad_norm': 1.4194040298461914, 'learning_rate': 7.9e-06, 'epoch': 0.08}
{'loss': 1.291, 'grad_norm': 1.3050247430801392, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.08}
{'loss': 1.1523, 'grad_norm': 2.2691779136657715, 'learning_rate': 7.7e-06, 'epoch': 0.09}
{'loss': 1.3719, 'grad_norm': 1.5343912839889526, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.09}
{'loss': 1.2264, 'grad_norm': 1.5394141674041748, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.09}
{'loss': 1.3695, 'grad_norm': 1.4285556077957153, 'learning_rate': 7.4e-06, 'epoch': 0.1}
{'loss': 1.384, 'grad_norm': 1.80894136428833, 'learning_rate': 7.3e-06, 'epoch': 0.1}
{'loss': 1.3613, 'grad_norm': 2.1463305950164795, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.1}
{'loss': 1.2527, 'grad_norm': 2.510646343231201, 'learning_rate': 7.100000000000001e-06, 'epoch': 0.11}
{'loss': 1.3539, 'grad_norm': 2.392282247543335, 'learning_rate': 7e-06, 'epoch': 0.11}
{'loss': 1.1092, 'grad_norm': 1.573515772819519, 'learning_rate': 6.9e-06, 'epoch': 0.12}
{'loss': 1.06, 'grad_norm': 1.4680829048156738, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.12}
{'loss': 1.4594, 'grad_norm': 1.4962959289550781, 'learning_rate': 6.700000000000001e-06, 'epoch': 0.12}
{'loss': 1.2762, 'grad_norm': 1.7487889528274536, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.13}
{'loss': 1.3699, 'grad_norm': 2.6125168800354004, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.13}
{'loss': 1.2695, 'grad_norm': 1.4249179363250732, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.13}
{'loss': 1.393, 'grad_norm': 1.966158151626587, 'learning_rate': 6.300000000000001e-06, 'epoch': 0.14}
{'loss': 1.1686, 'grad_norm': 1.7168519496917725, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.14}
{'loss': 1.5469, 'grad_norm': 1.7952702045440674, 'learning_rate': 6.1e-06, 'epoch': 0.14}
{'loss': 1.1479, 'grad_norm': 1.576263189315796, 'learning_rate': 6e-06, 'epoch': 0.15}
{'loss': 1.3391, 'grad_norm': 1.4978539943695068, 'learning_rate': 5.9e-06, 'epoch': 0.15}
{'loss': 1.3543, 'grad_norm': 1.6384111642837524, 'learning_rate': 5.8e-06, 'epoch': 0.16}
{'loss': 1.2742, 'grad_norm': 1.5904899835586548, 'learning_rate': 5.7e-06, 'epoch': 0.16}
{'loss': 1.3805, 'grad_norm': 1.8489811420440674, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.16}
{'loss': 1.0398, 'grad_norm': 1.5756850242614746, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.17}
{'loss': 1.2197, 'grad_norm': 1.4772545099258423, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.17}
{'loss': 1.4578, 'grad_norm': 1.3743460178375244, 'learning_rate': 5.300000000000001e-06, 'epoch': 0.17}
{'loss': 1.1746, 'grad_norm': 1.579722285270691, 'learning_rate': 5.2e-06, 'epoch': 0.18}
{'loss': 1.1941, 'grad_norm': 1.6170941591262817, 'learning_rate': 5.1e-06, 'epoch': 0.18}
{'loss': 1.3242, 'grad_norm': 1.4691075086593628, 'learning_rate': 5e-06, 'epoch': 0.19}
{'loss': 1.5078, 'grad_norm': 1.5524446964263916, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.19}
{'loss': 1.5516, 'grad_norm': 1.6203957796096802, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.19}
{'loss': 1.3217, 'grad_norm': 1.4307951927185059, 'learning_rate': 4.7e-06, 'epoch': 0.2}
{'loss': 1.3879, 'grad_norm': 1.483506441116333, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.2}
{'loss': 1.1635, 'grad_norm': 1.7907016277313232, 'learning_rate': 4.5e-06, 'epoch': 0.2}
{'loss': 1.4609, 'grad_norm': 2.4740822315216064, 'learning_rate': 4.4e-06, 'epoch': 0.21}
{'loss': 1.4555, 'grad_norm': 1.5109120607376099, 'learning_rate': 4.3e-06, 'epoch': 0.21}
{'loss': 1.3172, 'grad_norm': 2.2133634090423584, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.22}
{'loss': 1.2336, 'grad_norm': 2.4027531147003174, 'learning_rate': 4.1e-06, 'epoch': 0.22}
{'loss': 1.0832, 'grad_norm': 1.6614677906036377, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.22}
{'loss': 1.3672, 'grad_norm': 1.6601665019989014, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.23}
{'loss': 1.3473, 'grad_norm': 1.9695998430252075, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.23}
{'loss': 1.3092, 'grad_norm': 2.1182701587677, 'learning_rate': 3.7e-06, 'epoch': 0.23}
{'loss': 1.3203, 'grad_norm': 1.777315616607666, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.24}
{'loss': 1.2227, 'grad_norm': 1.542165994644165, 'learning_rate': 3.5e-06, 'epoch': 0.24}
{'loss': 1.2746, 'grad_norm': 1.7191613912582397, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.25}
{'loss': 1.5227, 'grad_norm': 1.5825824737548828, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.25}
{'loss': 1.2205, 'grad_norm': 1.6447373628616333, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.25}
{'loss': 1.3813, 'grad_norm': 1.695857286453247, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.26}
{'loss': 1.4492, 'grad_norm': 2.28294038772583, 'learning_rate': 3e-06, 'epoch': 0.26}
{'loss': 1.2111, 'grad_norm': 2.3682897090911865, 'learning_rate': 2.9e-06, 'epoch': 0.26}
{'loss': 1.3965, 'grad_norm': 1.6493382453918457, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.27}
{'loss': 1.3906, 'grad_norm': 2.5332400798797607, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.27}
{'loss': 1.2242, 'grad_norm': 1.73280930519104, 'learning_rate': 2.6e-06, 'epoch': 0.28}
{'loss': 1.2641, 'grad_norm': 2.6915383338928223, 'learning_rate': 2.5e-06, 'epoch': 0.28}
{'loss': 1.2131, 'grad_norm': 1.7507878541946411, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.28}
{'loss': 1.3225, 'grad_norm': 1.5935834646224976, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.29}
{'loss': 1.2363, 'grad_norm': 2.0205698013305664, 'learning_rate': 2.2e-06, 'epoch': 0.29}
{'loss': 1.3639, 'grad_norm': 2.4854397773742676, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.29}
{'loss': 1.3355, 'grad_norm': 1.6910303831100464, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.3}
{'loss': 1.2465, 'grad_norm': 1.8511475324630737, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.3}
{'loss': 1.2205, 'grad_norm': 2.1553609371185303, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.3}
{'loss': 1.2164, 'grad_norm': 2.1741912364959717, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.31}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 840/1000 [05:40<01:02,  2.58it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 841/1000 [05:41<01:01,  2.57it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842/1000 [05:41<01:06,  2.36it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 843/1000 [05:42<01:07,  2.34it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 844/1000 [05:42<01:07,  2.32it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 845/1000 [05:42<01:03,  2.44it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 846/1000 [05:43<01:03,  2.41it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847/1000 [05:43<01:02,  2.44it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 848/1000 [05:44<01:00,  2.52it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 849/1000 [05:44<01:00,  2.51it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 850/1000 [05:44<00:57,  2.59it/s]                                                   85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 850/1000 [05:44<00:57,  2.59it/s]Saving model checkpoint to ./output/checkpoint-850
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 851/1000 [05:45<01:01,  2.44it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852/1000 [05:45<01:01,  2.40it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 853/1000 [05:46<01:00,  2.44it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 854/1000 [05:46<00:59,  2.46it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 855/1000 [05:46<00:56,  2.55it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 856/1000 [05:47<00:54,  2.63it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857/1000 [05:47<00:57,  2.51it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 858/1000 [05:48<00:56,  2.51it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 859/1000 [05:48<00:55,  2.52it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860/1000 [05:48<00:55,  2.52it/s]                                                   86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860/1000 [05:48<00:55,  2.52it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 861/1000 [05:49<00:55,  2.51it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 862/1000 [05:49<00:55,  2.51it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 863/1000 [05:50<00:54,  2.49it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 864/1000 [05:50<00:53,  2.56it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 865/1000 [05:50<00:53,  2.54it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 866/1000 [05:51<00:51,  2.59it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867/1000 [05:51<00:51,  2.58it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 868/1000 [05:52<00:56,  2.32it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 869/1000 [05:52<00:55,  2.38it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870/1000 [05:52<00:53,  2.42it/s]                                                   87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870/1000 [05:52<00:53,  2.42it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 871/1000 [05:53<00:52,  2.46it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872/1000 [05:53<00:51,  2.48it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 873/1000 [05:54<00:49,  2.55it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 874/1000 [05:54<00:49,  2.54it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875/1000 [05:54<00:48,  2.59it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 876/1000 [05:55<00:47,  2.63it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 877/1000 [05:55<00:47,  2.60it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878/1000 [05:55<00:45,  2.66it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 879/1000 [05:56<00:46,  2.62it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 880/1000 [05:56<00:47,  2.52it/s]                                                   88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 880/1000 [05:56<00:47,  2.52it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 881/1000 [05:57<00:47,  2.52it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 882/1000 [05:57<00:46,  2.52it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883/1000 [05:57<00:47,  2.44it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 884/1000 [05:58<00:48,  2.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 885/1000 [05:58<00:47,  2.42it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 886/1000 [05:59<00:46,  2.45it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 887/1000 [05:59<00:45,  2.47it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 888/1000 [05:59<00:45,  2.49it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 889/1000 [06:00<00:44,  2.48it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890/1000 [06:00<00:45,  2.42it/s]                                                   89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890/1000 [06:00<00:45,  2.42it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 891/1000 [06:01<00:44,  2.44it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 892/1000 [06:01<00:47,  2.26it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 893/1000 [06:02<00:44,  2.39it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 894/1000 [06:02<00:42,  2.48it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 895/1000 [06:02<00:42,  2.49it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896/1000 [06:03<00:41,  2.51it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 897/1000 [06:03<00:41,  2.50it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898/1000 [06:04<00:41,  2.43it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 899/1000 [06:04<00:41,  2.46it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 900/1000 [06:04<00:40,  2.49it/s]                                                   90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 900/1000 [06:04<00:40,  2.49it/s]Saving model checkpoint to ./output/checkpoint-900
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 901/1000 [06:05<00:39,  2.51it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 902/1000 [06:05<00:40,  2.43it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 903/1000 [06:06<00:38,  2.51it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 904/1000 [06:06<00:39,  2.44it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 905/1000 [06:06<00:37,  2.52it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906/1000 [06:07<00:38,  2.45it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 907/1000 [06:07<00:38,  2.40it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908/1000 [06:08<00:37,  2.43it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 909/1000 [06:08<00:37,  2.45it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 910/1000 [06:09<00:37,  2.39it/s]                                                   91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 910/1000 [06:09<00:37,  2.39it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 911/1000 [06:09<00:36,  2.42it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 912/1000 [06:09<00:36,  2.44it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913/1000 [06:10<00:31,  2.73it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 914/1000 [06:10<00:35,  2.45it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 915/1000 [06:10<00:34,  2.48it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 916/1000 [06:11<00:32,  2.58it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 917/1000 [06:11<00:32,  2.57it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 918/1000 [06:12<00:32,  2.54it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 919/1000 [06:12<00:32,  2.47it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 920/1000 [06:12<00:32,  2.48it/s]                                                   92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 920/1000 [06:12<00:32,  2.48it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921/1000 [06:13<00:31,  2.48it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 922/1000 [06:13<00:30,  2.57it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 923/1000 [06:14<00:30,  2.55it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 924/1000 [06:14<00:29,  2.54it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 925/1000 [06:14<00:29,  2.54it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 926/1000 [06:15<00:29,  2.52it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 927/1000 [06:15<00:29,  2.51it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 928/1000 [06:16<00:29,  2.44it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929/1000 [06:16<00:28,  2.48it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 930/1000 [06:16<00:27,  2.58it/s]                                                   93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 930/1000 [06:16<00:27,  2.58it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 931/1000 [06:17<00:26,  2.56it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 932/1000 [06:17<00:27,  2.47it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 933/1000 [06:18<00:26,  2.49it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 934/1000 [06:18<00:26,  2.48it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 935/1000 [06:18<00:25,  2.57it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936/1000 [06:19<00:24,  2.56it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 937/1000 [06:19<00:24,  2.55it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 938/1000 [06:20<00:24,  2.54it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939/1000 [06:20<00:24,  2.53it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 940/1000 [06:20<00:25,  2.34it/s]                                                   94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 940/1000 [06:20<00:25,  2.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 941/1000 [06:21<00:24,  2.45it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942/1000 [06:21<00:23,  2.46it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 943/1000 [06:22<00:23,  2.47it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944/1000 [06:22<00:22,  2.55it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 945/1000 [06:22<00:22,  2.47it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 946/1000 [06:23<00:21,  2.50it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947/1000 [06:23<00:21,  2.50it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 948/1000 [06:24<00:20,  2.50it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 949/1000 [06:24<00:19,  2.57it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 950/1000 [06:24<00:19,  2.56it/s]                                                   95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 950/1000 [06:24<00:19,  2.56it/s]Saving model checkpoint to ./output/checkpoint-950
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}

/root/miniconda3/envs/glm4-demo/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 951/1000 [06:25<00:20,  2.41it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 952/1000 [06:25<00:19,  2.45it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 953/1000 [06:26<00:18,  2.50it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954/1000 [06:26<00:17,  2.58it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 955/1000 [06:26<00:17,  2.55it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 956/1000 [06:27<00:17,  2.55it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957/1000 [06:27<00:16,  2.56it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 958/1000 [06:28<00:16,  2.55it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 959/1000 [06:28<00:16,  2.45it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960/1000 [06:28<00:16,  2.40it/s]                                                   96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960/1000 [06:28<00:16,  2.40it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 961/1000 [06:29<00:15,  2.51it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 962/1000 [06:29<00:15,  2.44it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 963/1000 [06:30<00:15,  2.45it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 964/1000 [06:30<00:14,  2.41it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 965/1000 [06:31<00:15,  2.20it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 966/1000 [06:31<00:15,  2.23it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967/1000 [06:31<00:14,  2.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 968/1000 [06:32<00:13,  2.39it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 969/1000 [06:32<00:12,  2.42it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 970/1000 [06:33<00:12,  2.44it/s]                                                   97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 970/1000 [06:33<00:12,  2.44it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 971/1000 [06:33<00:11,  2.45it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972/1000 [06:33<00:11,  2.48it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 973/1000 [06:34<00:11,  2.41it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 974/1000 [06:34<00:10,  2.43it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975/1000 [06:35<00:09,  2.53it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 976/1000 [06:35<00:09,  2.46it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 977/1000 [06:35<00:09,  2.49it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 978/1000 [06:36<00:08,  2.51it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 979/1000 [06:36<00:08,  2.45it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980/1000 [06:37<00:08,  2.46it/s]                                                   98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980/1000 [06:37<00:08,  2.46it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 981/1000 [06:37<00:07,  2.42it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 982/1000 [06:38<00:07,  2.39it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983/1000 [06:38<00:07,  2.43it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 984/1000 [06:38<00:06,  2.54it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 985/1000 [06:39<00:05,  2.61it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 986/1000 [06:39<00:05,  2.65it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 987/1000 [06:39<00:04,  2.71it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 988/1000 [06:40<00:04,  2.57it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 989/1000 [06:40<00:04,  2.34it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990/1000 [06:41<00:04,  2.39it/s]                                                   99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990/1000 [06:41<00:04,  2.39it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 991/1000 [06:41<00:03,  2.49it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 992/1000 [06:41<00:03,  2.50it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 993/1000 [06:42<00:02,  2.43it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 994/1000 [06:42<00:02,  2.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 995/1000 [06:43<00:02,  2.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 996/1000 [06:43<00:01,  2.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 997/1000 [06:43<00:01,  2.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998/1000 [06:44<00:00,  2.59it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 999/1000 [06:44<00:00,  2.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [06:45<00:00,  2.51it/s]                                                   100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [06:45<00:00,  2.51it/s]Saving model checkpoint to ./output/checkpoint-1000
loading configuration file /root/autodl-tmp/data/ZhipuAI/glm-4-9b-chat/config.json
Model config ChatGLMConfig {
  "_name_or_path": "THUDM/glm-4-9b-chat",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": [
    151329,
    151336,
    151338
  ],
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1.5625e-07,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_hidden_layers": 40,
  "num_layers": 40,
  "original_rope": true,
  "pad_token_id": 151329,
  "padded_vocab_size": 151552,
  "post_layer_norm": true,
  "rmsnorm": true,
  "rope_ratio": 500,
  "seq_length": 131072,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.43.3",
  "use_cache": true,
  "vocab_size": 151552
}



Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [06:45<00:00,  2.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [06:45<00:00,  2.47it/s]

***** Running Prediction *****
  Num examples = 1
  Batch size = 4
{'loss': 1.2549, 'grad_norm': 1.582887053489685, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.31}
{'loss': 1.1371, 'grad_norm': 2.8286678791046143, 'learning_rate': 1.5e-06, 'epoch': 0.32}
{'loss': 1.352, 'grad_norm': 1.647103190422058, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.32}
{'loss': 1.4049, 'grad_norm': 1.6424273252487183, 'learning_rate': 1.3e-06, 'epoch': 0.32}
{'loss': 1.3256, 'grad_norm': 1.6624667644500732, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.33}
{'loss': 1.2041, 'grad_norm': 1.586791753768921, 'learning_rate': 1.1e-06, 'epoch': 0.33}
{'loss': 1.1078, 'grad_norm': 1.8336498737335205, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.33}
{'loss': 1.2773, 'grad_norm': 1.6861563920974731, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.34}
{'loss': 1.357, 'grad_norm': 1.8026243448257446, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.34}
{'loss': 1.2293, 'grad_norm': 2.7825679779052734, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.35}
{'loss': 1.0486, 'grad_norm': 1.5542677640914917, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.35}
{'loss': 1.142, 'grad_norm': 3.1035051345825195, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.35}
{'loss': 1.3432, 'grad_norm': 1.5427534580230713, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.36}
{'loss': 1.4352, 'grad_norm': 1.5615593194961548, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.36}
{'loss': 1.2523, 'grad_norm': 2.037004232406616, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.36}
{'loss': 1.1953, 'grad_norm': 1.84739089012146, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.37}
{'loss': 1.3707, 'grad_norm': 1.6771049499511719, 'learning_rate': 0.0, 'epoch': 0.37}
{'train_runtime': 405.3212, 'train_samples_per_second': 2.467, 'train_steps_per_second': 2.467, 'train_loss': 1.3054296875, 'epoch': 0.37}
  0%|          | 0/1 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 0.669 seconds.
Prefix dict has been built successfully.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.18s/it]
